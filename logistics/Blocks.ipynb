{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import importlib as imp\n",
    "\n",
    "from collections import namedtuple\n",
    "from random import sample, shuffle\n",
    "from functools import reduce\n",
    "from itertools import accumulate\n",
    "from math import floor, ceil, sqrt, log, pi\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers, utils, losses, models as mds, optimizers\n",
    "\n",
    "if imp.util.find_spec('aggdraw'): import aggdraw\n",
    "if imp.util.find_spec('tensorflow_addons'): from tensorflow_addons import layers as tfa_layers\n",
    "if imp.util.find_spec('tensorflow_models'): from official.vision.beta.ops import augment as visaugment\n",
    "if imp.util.find_spec('tensorflow_probability'): from tensorflow_probability import distributions as tfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Invariant Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sic_block(input_tensor, filters, strides, padding, activation):\n",
    "    def variant_dims(size):\n",
    "        n_variants = ceil(log(ceil(sqrt(size)), pi))\n",
    "        return list(map(lambda x: 3**x, range(1, n_variants+1)))\n",
    "\n",
    "    def make_layer(size):\n",
    "        kwargs = dict(strides=strides, padding=padding)\n",
    "        return layers.Conv2D(filters, size, **kwargs)\n",
    "\n",
    "    size = min(input_tensor.shape[1:-1])\n",
    "    variants = variant_dims(size)\n",
    "    conv_layers = map(make_layer, variants)\n",
    "    conv_outputs = list(map(lambda x: x(input_tensor), conv_layers))\n",
    "    merged = tf.concat(conv_outputs, axis=-1)\n",
    "    normalized = layers.BatchNormalization()(merged)\n",
    "    output = layers.Activation(activation)(normalized)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(layers.Layer):\n",
    "    def __init__(self, filters, ratio=2):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.block = tf.keras.Sequential([\n",
    "            layers.GlobalAveragePooling2D(), # Squeeze\n",
    "            layers.Dense(filters//ratio, activation='relu'),\n",
    "            layers.Dense(filters, activation='sigmoid'), # Excite\n",
    "            layers.Reshape([1, 1, filters]),\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs * self.block(inputs)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return dict(filters=self.filters, ratio=self.ratio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "INITIAL_WIDTH = 64\n",
    "N_ENCODERS = 2\n",
    "DROPOUT_RATE = 0.6\n",
    "DEBUG = False\n",
    "\n",
    "def encoder_block(input, width_multiplier, name='block'):\n",
    "    conv_1 = layers.Conv2D(INITIAL_WIDTH*width_multiplier,\n",
    "                           (3, 3), activation=\"relu\", padding=\"valid\")(input)\n",
    "    conv_2 = layers.Conv2D(INITIAL_WIDTH*width_multiplier,\n",
    "                           (3, 3), activation=\"relu\", padding=\"valid\")(conv_1)\n",
    "    pool = layers.MaxPooling2D((2, 2))(conv_2)\n",
    "    dropout = layers.Dropout(DROPOUT_RATE)(pool)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(name, input.shape, conv_1.shape, conv_2.shape, pool.shape)\n",
    "\n",
    "    return dropout\n",
    "\n",
    "def decoder_block(input, skip_input, width_multiplier, name='block'):\n",
    "    conv_transpose = layers.Conv2DTranspose(\n",
    "        INITIAL_WIDTH*width_multiplier, (3, 3), strides=(2, 2), padding='same')(input)\n",
    "\n",
    "    cropped_skip_input = central_crop(skip_input, conv_transpose.shape[1])\n",
    "    conv_input = layers.Concatenate()([conv_transpose, cropped_skip_input])\n",
    "\n",
    "    conv_1 = layers.Conv2D(INITIAL_WIDTH*width_multiplier,\n",
    "                           (3, 3), activation=\"relu\", padding=\"valid\")(conv_input)\n",
    "    conv_2 = layers.Conv2D(INITIAL_WIDTH*width_multiplier,\n",
    "                           (3, 3), activation=\"relu\", padding=\"valid\")(conv_1)\n",
    "    dropout = layers.Dropout(DROPOUT_RATE)(conv_2)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(name, conv_input.shape, conv_1.shape, conv_2.shape)\n",
    "\n",
    "    return dropout\n",
    "\n",
    "def central_crop(x, target_size):\n",
    "    current_size = x.shape[1]\n",
    "    extra_size = current_size - target_size\n",
    "    start = extra_size//2\n",
    "    end = start+target_size\n",
    "    return x[:, start:end, start:end, :]\n",
    "\n",
    "def resize_block(input):\n",
    "    conv_transpose_1 = layers.Conv2DTranspose(\n",
    "        8, (3, 3), strides=(2, 2), padding='same')(input)\n",
    "    conv_transpose_2 = layers.Conv2DTranspose(\n",
    "        1, (3, 3), strides=(2, 2), padding='same')(conv_transpose_1)\n",
    "    \n",
    "    cropped = central_crop(conv_transpose_2, IMG_SIZE)\n",
    "                                    \n",
    "    return cropped"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
