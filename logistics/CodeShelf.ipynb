{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Shelf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shelf = shelve.open('CodeShelf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add or Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def plot_history(h):\n",
      "    fig, axes = plt.subplots(1, 2, figsize=(10, 5), facecolor='w', edgecolor='k')\n",
      "\n",
      "    axes[0].plot(h['loss'], label='Loss')\n",
      "    axes[0].plot(h['val_loss'], label='Validation Loss')\n",
      "\n",
      "    axes[0].set_xlabel('Epoch')\n",
      "    axes[0].set_ylabel('Loss')\n",
      "    axes[0].set_title('Losses')\n",
      "\n",
      "    axes[1].plot(h['accuracy'], label='Accuracy')\n",
      "    axes[1].plot(h['val_accuracy'], label='Validation Accuracy')\n",
      "\n",
      "    axes[1].set_xlabel('Epoch')\n",
      "    axes[1].set_ylabel('Accuracy')\n",
      "    axes[1].set_title('Accuracies')\n",
      "\n",
      "    fig.legend()\n",
      "\n",
      "def run_summary(h):\n",
      "    plot_history(h)\n",
      "    print(max(h['accuracy']), '|', max(h['val_accuracy']))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value = \"\"\"\n",
    "def metric_name(output_name, set_name, metric_name):\n",
    "    parts = [set_name, output_name, metric_name]\n",
    "    name = reduce(lambda x, y: x + '_' + y if x else y , parts, '')\n",
    "    return name\n",
    "\n",
    "def plot_history(h, outputs=['']):\n",
    "    fig, axes = plt.subplots(len(outputs), 2, figsize=(12, 5*len(outputs)), facecolor='w', edgecolor='k')\n",
    "\n",
    "    def plot(ax, output, metric):\n",
    "        label = '{} {}'.format(output, metric).strip().capitalize()\n",
    "        data = h[metric_name(output, '', metric)]\n",
    "        ax.plot(data, label=label)\n",
    "        ax.scatter([np.argmax(data), np.argmin(data)], [max(data), min(data)])\n",
    "\n",
    "        vlabel = '{} validation {}'.format(output, metric).strip().capitalize()\n",
    "        data = h[metric_name(output, 'val', metric)]\n",
    "        ax.plot(data, label=vlabel)\n",
    "        ax.scatter([np.argmax(data), np.argmin(data)], [max(data), min(data)])\n",
    "\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel(metric.capitalize())\n",
    "        ax.set_title('{} {}'.format(output, metric).strip().capitalize())\n",
    "        ax.legend()\n",
    "\n",
    "    for idx,o in enumerate(outputs):\n",
    "        if len(outputs) == 1:\n",
    "            plot(axes[0], o, 'loss')\n",
    "            plot(axes[1], o, 'accuracy')\n",
    "        else:\n",
    "            plot(axes[idx, 0], o, 'loss')\n",
    "            plot(axes[idx, 1], o, 'accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # fig.legend()\n",
    "\n",
    "def run_summary(h, outputs=['']):\n",
    "    plot_history(h, outputs)\n",
    "    for o in outputs:\n",
    "        print(o + ': ' if o else '', max(h[metric_name(o, '', 'accuracy')]), '|', max(h[metric_name(o, 'val', 'accuracy')]))\n",
    "\"\"\"\n",
    "\n",
    "key = 'run_summary'\n",
    "\n",
    "print(shelf.get(key))\n",
    "shelf[key] = value\n",
    "shelf.sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 ['plot_history', 'model_summary', 'run_summary', 'tf_imports', 'basic_image_augmentations', 'image_randaugment']\n"
     ]
    }
   ],
   "source": [
    "keys = list(shelf.keys())\n",
    "print(len(keys), keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def metric_name(output_name, set_name, metric_name):\n",
      "    parts = [set_name, output_name, metric_name]\n",
      "    name = reduce(lambda x, y: x + '_' + y if x else y , parts, '')\n",
      "    return name\n",
      "\n",
      "def plot_history(h, outputs=['']):\n",
      "    fig, axes = plt.subplots(len(outputs), 2, figsize=(12, 5*len(outputs)), facecolor='w', edgecolor='k')\n",
      "\n",
      "    def plot(ax, output, metric):\n",
      "        label = '{} {}'.format(output, metric).strip().capitalize()\n",
      "        data = h[metric_name(output, '', metric)]\n",
      "        ax.plot(data, label=label)\n",
      "        ax.scatter([np.argmax(data), np.argmin(data)], [max(data), min(data)])\n",
      "\n",
      "        vlabel = '{} validation {}'.format(output, metric).strip().capitalize()\n",
      "        data = h[metric_name(output, 'val', metric)]\n",
      "        ax.plot(data, label=vlabel)\n",
      "        ax.scatter([np.argmax(data), np.argmin(data)], [max(data), min(data)])\n",
      "\n",
      "        ax.set_xlabel('Epoch')\n",
      "        ax.set_ylabel(metric.capitalize())\n",
      "        ax.set_title('{} {}'.format(output, metric).strip().capitalize())\n",
      "        ax.legend()\n",
      "\n",
      "    for idx,o in enumerate(outputs):\n",
      "        if len(outputs) == 1:\n",
      "            plot(axes[0], o, 'loss')\n",
      "            plot(axes[1], o, 'accuracy')\n",
      "        else:\n",
      "            plot(axes[idx, 0], o, 'loss')\n",
      "            plot(axes[idx, 1], o, 'accuracy')\n",
      "\n",
      "    plt.tight_layout()\n",
      "    # fig.legend()\n",
      "\n",
      "def run_summary(h, outputs=['']):\n",
      "    plot_history(h, outputs)\n",
      "    for o in outputs:\n",
      "        print(o + ': ' if o else '', max(h[metric_name(o, '', 'accuracy')]), '|', max(h[metric_name(o, 'val', 'accuracy')]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(shelf['run_summary'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "472baa808a066784c660228b7522f02c55b99d16f672674ca10b75b514659298"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
