{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Epoch Training Using Gradient Tape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mean(metrics.Metric):\n",
    "    def __init__(self, name=\"mean\", **kwargs):\n",
    "        super(Mean, self).__init__(name=name, **kwargs)\n",
    "        self.total = self.add_weight(name='total_{}'.format(name), initializer=\"zeros\")\n",
    "        self.count = self.add_weight(name='count_{}'.format(name), initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, result):\n",
    "        self.total.assign_add(result)\n",
    "        self.count.assign_add(1)\n",
    "\n",
    "    def result(self):\n",
    "        return self.total/self.count\n",
    "\n",
    "    def reset_state(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.total.assign(0.0)\n",
    "        self.count.assign(0)\n",
    "\n",
    "class History(object):\n",
    "    def __init__(self):\n",
    "        self.metrics = dict(\n",
    "            learning_rate = Mean(name='learning_rate'),\n",
    "\n",
    "            loss = Mean(name='loss'),\n",
    "            val_loss = Mean(name='val_loss'),\n",
    "\n",
    "            yx_loss = Mean(name='yx_loss'),\n",
    "            val_yx_loss = Mean(name='val_yx_loss'),\n",
    "\n",
    "            hw_loss = Mean(name='hw_loss'),\n",
    "            val_hw_loss = Mean(name='val_hw_loss'),\n",
    "\n",
    "            iou = Mean(name='iou'),\n",
    "            val_iou = Mean(name='val_iou'),\n",
    "\n",
    "            positive_iou = Mean(name='positive_iou'),\n",
    "            val_positive_iou = Mean(name='val_positive_iou'),\n",
    "\n",
    "            negative_iou = Mean(name='negative_iou'),\n",
    "            val_negative_iou = Mean(name='val_negative_iou'),\n",
    "        )\n",
    "        self.history = {name: [] for name, metric in self.metrics.items()}\n",
    "    \n",
    "    @property\n",
    "    def metric_names(self):\n",
    "        return list(self.metrics.keys())\n",
    "\n",
    "    @property\n",
    "    def training_metrics_names(self):\n",
    "        return list(filter(lambda name: not name.startswith('val_'), self.metrics.keys()))\n",
    "    \n",
    "    @property\n",
    "    def training_metrics(self):\n",
    "        return [(name, self.metrics[name].result()) for name in self.training_metrics_names]\n",
    "\n",
    "    @property\n",
    "    def metric_values(self):\n",
    "        return [(name, metric.result()) for name, metric in self.metrics.items()]\n",
    "    \n",
    "    def train_step(self, yx_loss, hw_loss, iou, positive_iou, negative_iou):\n",
    "        self.metrics['loss'].update_state(yx_loss + hw_loss)\n",
    "        self.metrics['yx_loss'].update_state(yx_loss)\n",
    "        self.metrics['hw_loss'].update_state(hw_loss)\n",
    "\n",
    "        self.metrics['iou'].update_state(iou)\n",
    "        self.metrics['positive_iou'].update_state(positive_iou)\n",
    "        self.metrics['negative_iou'].update_state(negative_iou)\n",
    "\n",
    "        return self.training_metrics\n",
    "    \n",
    "    def val_step(self, yx_loss, hw_loss, iou, positive_iou, negative_iou):\n",
    "        self.metrics['val_loss'].update_state(yx_loss + hw_loss)\n",
    "        self.metrics['val_yx_loss'].update_state(yx_loss)\n",
    "        self.metrics['val_hw_loss'].update_state(hw_loss)\n",
    "\n",
    "        self.metrics['val_iou'].update_state(iou)\n",
    "        self.metrics['val_positive_iou'].update_state(positive_iou)\n",
    "        self.metrics['val_negative_iou'].update_state(negative_iou)\n",
    "\n",
    "        return self.metric_values\n",
    "    \n",
    "    def learning_rate(self, lr_value):\n",
    "        self.metrics['learning_rate'].update_state(lr_value)\n",
    "    \n",
    "    def epoch(self):\n",
    "        # Record the current epoch values before reset.\n",
    "        values = self.metric_values\n",
    "\n",
    "        for name in self.metrics.keys():\n",
    "            self.record_and_reset(name)\n",
    "        \n",
    "        return values\n",
    "    \n",
    "    def record_and_reset(self, name):\n",
    "        self.history[name].append(self.metrics[name].result().numpy())\n",
    "        self.metrics[name].reset_state()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        yx_loss, hw_loss = model.loss(y, logits)\n",
    "        loss = yx_loss + hw_loss\n",
    "        iou, positive_iou, negative_iou = compute_iou_metric(y, logits)\n",
    "\n",
    "    # Compute gradients and backpropagate.\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    model.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    return yx_loss, hw_loss, iou, positive_iou, negative_iou\n",
    "\n",
    "@tf.function\n",
    "def val_step(model, x, y):\n",
    "    logits = model(x, training=False)\n",
    "    yx_loss, hw_loss = model.loss(y, logits)\n",
    "    iou, positive_iou, negative_iou = compute_iou_metric(y, logits)\n",
    "    \n",
    "    return yx_loss, hw_loss, iou, positive_iou, negative_iou\n",
    "\n",
    "def train(model, tds, vds, epochs=100):\n",
    "    # Record progress\n",
    "    ckpt = tf.train.Checkpoint(optimizer=model.optimizer, model=model)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, './sequence_of_bboxes', max_to_keep=3)\n",
    "    history = History()\n",
    "    \n",
    "    # tds = tds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    # vds = vds.prefetch(buffer_size=tf.data.AUTOTUNE) if vds else None\n",
    "    tds = tds.prefetch(buffer_size=tf.data.AUTOTUNE).take(2)\n",
    "    vds = vds.prefetch(buffer_size=tf.data.AUTOTUNE).take(2) if vds else None\n",
    "    # tds = tds.prefetch(buffer_size=tf.data.AUTOTUNE).take(1)\n",
    "    # vds = vds.prefetch(buffer_size=tf.data.AUTOTUNE).take(1) if vds else None\n",
    "\n",
    "    history.learning_rate(LEARNING_RATE)\n",
    "    history.record_and_reset('learning_rate')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Track training progress\n",
    "        print(\"\\nEpoch {}/{}\".format(epoch + 1, epochs))\n",
    "        p_bar = utils.Progbar(STEPS_PER_EPOCH, stateful_metrics=history.metric_names)\n",
    "        steps = 0\n",
    "\n",
    "        for step, (x, y) in enumerate(iter(tds)):\n",
    "            yx_loss, hw_loss, iou, positive_iou, negative_iou = train_step(model, x, y)\n",
    "\n",
    "            p_bar.update(step + 1, values=history.train_step(yx_loss, hw_loss, iou, positive_iou, negative_iou))\n",
    "            steps += 1\n",
    "        \n",
    "        # Record learning rates\n",
    "        history.learning_rate(model.optimizer.lr((epoch + 1)*STEPS_PER_EPOCH))\n",
    "        \n",
    "        for x, y in iter(vds):\n",
    "            yx_loss, hw_loss, iou, positive_iou, negative_iou = val_step(model, x, y)\n",
    "\n",
    "            history.val_step(yx_loss, hw_loss, iou, positive_iou, negative_iou)\n",
    "        \n",
    "        # Display metrics at the end of each epoch.\n",
    "        p_bar.update(steps, values=history.epoch())\n",
    "\n",
    "        # Save Checkpoint\n",
    "        print('\\nSaved Checkpoint: {}'.format(ckpt_manager.save()))\n",
    "\n",
    "\n",
    "    return history\n",
    "\n",
    "EPOCHS = 2\n",
    "# EPOCHS = 50\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "tds = train_prep_ds.batch(BATCH_SIZE)\n",
    "# vds = val_prep_ds.batch(256).cache()\n",
    "vds = val_prep_ds.batch(2).cache()\n",
    "\n",
    "hist = train(model, tds, vds, epochs=EPOCHS)\n",
    "hist.history"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "472baa808a066784c660228b7522f02c55b99d16f672674ca10b75b514659298"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
