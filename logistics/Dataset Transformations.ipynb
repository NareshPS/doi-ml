{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize and Scale Images and Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "\n",
    "@tf.function\n",
    "def resize_and_scale(item):\n",
    "    image, mask = item['image'], item['annotation']\n",
    "\n",
    "    # Resize image and mask to IMG_SIZE\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    mask = tf.image.resize(mask, [IMG_SIZE, IMG_SIZE])\n",
    "\n",
    "    # Normalize the image\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    # Round the mask values\n",
    "    mask = tf.cast(tf.math.round(mask), tf.uint16)\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Images and Masks to Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(images, masks, patch_size):\n",
    "    patch_count = (images.shape[1]//patch_size)**2\n",
    "    sizes=[1, patch_size, patch_size, 1]\n",
    "    kwargs = dict(sizes=sizes, strides=sizes, rates=[1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "    # Extract patches from  images\n",
    "    image_patches = tf.image.extract_patches(images, **kwargs)\n",
    "    image_patches = tf.reshape(image_patches, [-1, patch_count, patch_size, patch_size, 3])\n",
    "\n",
    "    # Extract patches from  masks\n",
    "    box_patches = tf.image.extract_patches(masks, **kwargs)\n",
    "    box_patches = tf.reshape(box_patches, [-1, patch_count, patch_size, patch_size, 2])\n",
    "\n",
    "\n",
    "    return image_patches, box_patches\n",
    "\n",
    "images, masks = tf.reshape(tf.range(16*256*256*3), (16, 256, 256, 3)), tf.reshape(tf.range(16*256*256*2), (16, 256, 256, 2))\n",
    "# images, masks = tf.reshape(tf.range(4*4*3), (1, 4, 4, 3)), tf.reshape(tf.range(4*4*2), (1, 4, 4, 2))\n",
    "image_patches, box_patches = extract_patches(images, masks, patch_size=2)\n",
    "\n",
    "print('Image: {} --> Patches: {}'.format(images.shape, image_patches.shape))\n",
    "print('Box: {} --> Patches: {}'.format(masks.shape, box_patches.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Images to Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_patch(images, patch_size):\n",
    "    grid_size = images.shape[1]//patch_size\n",
    "    patch_count = grid_size**2\n",
    "    sizes=[1, patch_size, patch_size, 1]\n",
    "    kwargs = dict(sizes=sizes, strides=sizes, rates=[1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "    # Extract patches from  images\n",
    "    image_patches = tf.image.extract_patches(images, **kwargs)\n",
    "    image_patches = tf.reshape(image_patches, [-1, patch_count, patch_size, patch_size, 3])\n",
    "\n",
    "    return image_patches\n",
    "\n",
    "batch_size, img_size, patch_size = 2, 16, 4\n",
    "input_shape = (batch_size, img_size, img_size, 3)\n",
    "images = tf.reshape(tf.range(reduce(operator.mul, input_shape)), input_shape)\n",
    "\n",
    "image_patches = batch_to_patch(images, patch_size=patch_size)\n",
    "print('Image: {} --> Patches: {}'.format(images.shape, image_patches.shape))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
