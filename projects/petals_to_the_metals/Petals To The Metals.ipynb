{"cells":[{"cell_type":"markdown","metadata":{},"source":["# A Simple TF 2.2 notebook\n","\n","This is intended as a simple, short introduction to the operations competitors will need to perform with TPUs.\n","\n","Current Version: 13"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-08T06:39:45.863797Z","iopub.status.busy":"2023-09-08T06:39:45.863423Z","iopub.status.idle":"2023-09-08T06:39:45.869661Z","shell.execute_reply":"2023-09-08T06:39:45.868777Z","shell.execute_reply.started":"2023-09-08T06:39:45.863768Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","import numpy as np\n","\n","from kaggle_datasets import KaggleDatasets\n","\n","print(f\"Tensorflow version: {tf.__version__}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Detect my accelerator"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T06:39:49.419473Z","iopub.status.busy":"2023-09-08T06:39:49.419101Z","iopub.status.idle":"2023-09-08T06:39:49.433580Z","shell.execute_reply":"2023-09-08T06:39:49.432450Z","shell.execute_reply.started":"2023-09-08T06:39:49.419443Z"},"trusted":true},"outputs":[],"source":["# Detect hardware, return appropriate distribution strategy\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","else:\n","    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","\n","print(f'Strategy: {strategy}')\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"]},{"cell_type":"markdown","metadata":{},"source":["# Get my data path"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T06:39:52.777769Z","iopub.status.busy":"2023-09-08T06:39:52.777385Z","iopub.status.idle":"2023-09-08T06:39:53.338752Z","shell.execute_reply":"2023-09-08T06:39:53.337775Z","shell.execute_reply.started":"2023-09-08T06:39:52.777733Z"},"trusted":true},"outputs":[],"source":["GCS_DS_PATH = KaggleDatasets().get_gcs_path() # you can list the bucket with \"!gsutil ls $GCS_DS_PATH\""]},{"cell_type":"markdown","metadata":{},"source":["# Set some parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T06:39:55.187216Z","iopub.status.busy":"2023-09-08T06:39:55.186789Z","iopub.status.idle":"2023-09-08T06:39:55.193946Z","shell.execute_reply":"2023-09-08T06:39:55.192687Z","shell.execute_reply.started":"2023-09-08T06:39:55.187173Z"},"trusted":true},"outputs":[],"source":["## Version: 1\n","# IMAGE_SIZE = [192, 192] # at this size, a GPU will run out of memory. Use the TPU\n","\n","## Version: 8\n","IMAGE_SIZE = [224, 224] # at this size, a GPU will run out of memory. Use the TPU\n","\n","## Version: 7\n","# INPUT_IMAGE_SIZE = [224, 224] # Model Input Shape\n","\n","## Version: 1\n","# EPOCHS = 5\n","\n","## Version: 4\n","# EPOCHS = 12\n","\n","## Version: 5\n","EPOCHS = 25\n","\n","BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n","\n","NUM_TRAINING_IMAGES = 12753\n","NUM_TEST_IMAGES = 7382\n","STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE"]},{"cell_type":"markdown","metadata":{},"source":["# Load my data\n","\n","This data is loaded from Kaggle and automatically sharded to maximize parallelization."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T06:39:59.728686Z","iopub.status.busy":"2023-09-08T06:39:59.728308Z","iopub.status.idle":"2023-09-08T06:40:00.563984Z","shell.execute_reply":"2023-09-08T06:40:00.562744Z","shell.execute_reply.started":"2023-09-08T06:39:59.728655Z"},"trusted":true},"outputs":[],"source":["# def decode_image(image_data):\n","#     image = tf.image.decode_jpeg(image_data, channels=3)\n","    \n","#     ## Version: 1\n","# #     image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n","    \n","#     image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n","\n","#     ## Version: 7\n","# #     image = tf.image.resize(image, INPUT_IMAGE_SIZE, method='nearest')\n","    \n","#     ## Version: 8\n","#     # image = tf.cast(image, tf.float32)\n","#     # image = (image - 127.5) / 127.5\n","    \n","#     return image\n","\n","def rescale_01(image, _):\n","    return tf.cast(image, tf.float32) / 255.0, _  # convert image to floats in [0, 1] range\n","\n","def rescale_11(image, _):\n","    image = tf.cast(image, tf.float32)\n","    image = (image - 127.5) / 127.5\n","    return image, _\n","\n","def read_labeled_tfrecord(example):\n","    LABELED_TFREC_FORMAT = {\n","        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n","        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n","    }\n","    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n","    image = decode_image(example['image'])\n","    label = tf.cast(example['class'], tf.int32)\n","    return image, label # returns a dataset of (image, label) pairs\n","\n","def read_unlabeled_tfrecord(example):\n","    UNLABELED_TFREC_FORMAT = {\n","        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n","        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n","        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n","    }\n","    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n","    image = decode_image(example['image'])\n","    idnum = example['id']\n","    return image, idnum # returns a dataset of image(s)\n","\n","def load_dataset(filenames, labeled=True, ordered=False, rescale='01'):\n","    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n","    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n","\n","    ignore_order = tf.data.Options()\n","    if not ordered:\n","        ignore_order.experimental_deterministic = False # disable order, increase speed\n","\n","    dataset = tf.data.TFRecordDataset(filenames) # automatically interleaves reads from multiple files\n","    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n","    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord)\n","    dataset = dataset.map(rescale_01 if rescale == '01' else rescale_11) # Rescale dataset\n","    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n","    return dataset\n","\n","def get_dataset_name(image_size):\n","    size = image_size[0]\n","    return f'/tfrecords-jpeg-{size}x{size}'\n","\n","def get_training_dataset(rescale='01'):\n","    ds_name = get_dataset_name(IMAGE_SIZE)\n","    dataset = load_dataset(\n","        tf.io.gfile.glob(f'{GCS_DS_PATH}{ds_name}/train/*.tfrec'), labeled=True, rescale=rescale\n","    )\n","    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n","    dataset = dataset.shuffle(2048)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    return dataset\n","\n","def get_validation_dataset(rescale='01'):\n","    ds_name = get_dataset_name(IMAGE_SIZE)\n","    dataset = load_dataset(\n","        tf.io.gfile.glob(f'{GCS_DS_PATH}{ds_name}/val/*.tfrec'),\n","        labeled=True,\n","        ordered=False,\n","        rescale=rescale\n","    )\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.cache()\n","    return dataset\n","\n","def get_test_dataset(rescale='01', ordered=False):\n","    ds_name = get_dataset_name(IMAGE_SIZE)\n","    dataset = load_dataset(\n","        tf.io.gfile.glob(f'{GCS_DS_PATH}{ds_name}/test/*.tfrec'),\n","        labeled=False,\n","        ordered=ordered,\n","        rescale=rescale\n","    )\n","    dataset = dataset.batch(BATCH_SIZE)\n","    return dataset\n","\n","training_dataset_01 = get_training_dataset()\n","validation_dataset_01 = get_validation_dataset()\n","\n","training_dataset_11 = get_training_dataset(rescale='11')\n","validation_dataset_11 = get_validation_dataset(rescale='11')"]},{"cell_type":"markdown","metadata":{},"source":["# Build a model on TPU (or GPU, or CPU...) with Tensorflow 2.1!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T06:42:48.482002Z","iopub.status.busy":"2023-09-08T06:42:48.481556Z","iopub.status.idle":"2023-09-08T06:42:57.598312Z","shell.execute_reply":"2023-09-08T06:42:57.597200Z","shell.execute_reply.started":"2023-09-08T06:42:48.481964Z"},"trusted":true},"outputs":[],"source":["## Version: 1\n","# with strategy.scope():    \n","#     pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n","#     pretrained_model.trainable = False # tramsfer learning\n","    \n","#     model = tf.keras.Sequential([\n","#         pretrained_model,\n","#         tf.keras.layers.GlobalAveragePooling2D(),\n","#         tf.keras.layers.Dense(104, activation='softmax')\n","#     ])\n","\n","## Version: 2\n","# try:\n","#     import autokeras as ak\n","#     print(f'[autokeras] Not Available')\n","# except:\n","#     ! pip install autokeras\n","\n","# import autokeras as ak\n","\n","# with strategy.scope():   \n","#     clf = ak.ImageClassifier()\n","#     clf.fit(training_dataset, validation_data=validation_dataset)\n","\n","## Version: 3\n","# try:\n","#     import tfimm\n","# except:\n","#     ! pip install tfimm timm\n","\n","# import tfimm\n","\n","# with strategy.scope():   \n","#     model = tfimm.create_model(\"vit_tiny_patch16_224\", pretrained=\"timm\", nb_classes=104)\n","\n","# preprocess = tfimm.create_preprocessing(\"vit_tiny_patch16_224\", dtype=\"float32\")\n","# model.compile(\n","#     optimizer='adam',\n","#     loss = 'sparse_categorical_crossentropy',\n","#     metrics=['sparse_categorical_accuracy']\n","# )\n","\n","# historical = model.fit(\n","#           training_dataset.map(lambda x,y: (preprocess(x), y)),\n","#           steps_per_epoch=STEPS_PER_EPOCH, \n","#           epochs=EPOCHS, \n","#           validation_data=validation_dataset)\n","\n","## Version: 4\n","# model_url = 'https://tfhub.dev/google/imagenet/mobilenet_v1_100_192/feature_vector/5'\n","\n","## Version: 6\n","# model_url = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_192/feature_vector/5'\n","\n","## Version: 7\n","# model_url = 'https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b0/feature_vector/2'\n","\n","## Version: 8\n","# model_url = 'https://tfhub.dev/sayakpaul/vit_b16_fe/1'\n","\n","## Version: 9\n","# model_url = 'https://tfhub.dev/sayakpaul/vit_s16_fe/1'\n","\n","## Version: 10\n","# model_url = 'https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5'\n","\n","## Version: 13\n","model_url = 'https://tfhub.dev/sayakpaul/vit_b8_fe/1'\n","\n","## Version: 7\n","with strategy.scope():\n","    model = tf.keras.Sequential(\n","        [\n","            hub.KerasLayer(\n","                model_url,\n","#                 trainable=True,\n","                trainable=False, # Version: 12\n","            ),\n","            tf.keras.layers.Dense(104, activation='softmax')\n","        ]\n","    )\n","\n","## Version: 4\n","# with strategy.scope():\n","#     model = tf.keras.Sequential(\n","#         [\n","#             hub.KerasLayer(\n","#                 model_url,\n","# #                 trainable=True,\n","#                 trainable=False, # Version: 11\n","#                 arguments=dict(batch_norm_momentum=0.997)\n","#             ),\n","#             tf.keras.layers.Dense(104, activation='softmax')\n","#         ]\n","#     )\n","\n","## Version: 1\n","model.compile(\n","    optimizer='adam',\n","    loss = 'sparse_categorical_crossentropy',\n","    metrics=['sparse_categorical_accuracy']\n",")\n","\n","historical = model.fit(training_dataset, \n","          steps_per_epoch=STEPS_PER_EPOCH, \n","          epochs=EPOCHS, \n","          validation_data=validation_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["# Compute your predictions on the test set!\n","\n","This will create a file that can be submitted to the competition."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_ds = get_test_dataset(ordered=True) # since we are splitting the dataset and iterating separately on images and ids, order matters.\n","\n","print('Computing predictions...')\n","test_images_ds = test_ds.map(lambda image, idnum: image)\n","probabilities = model.predict(test_images_ds) # Version: 1\n","# probabilities = clf.predict(test_images_ds) # Version: 2\n","\n","print(f'probabilities.shape: {probabilities.shape}')\n","predictions = np.argmax(probabilities, axis=-1)\n","\n","## Version: 13\n","predictions = predictions[2:]\n","\n","print(predictions, predictions.shape)\n","np.savetxt('predictions.txt', predictions, fmt='%d')\n","\n","print('Generating submission.csv file...')\n","test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n","test_ids = next(iter(test_ids_ds.batch(predictions.shape[0]))).numpy().astype('U') # all in one batch\n","\n","print(test_ids, test_ids.shape)\n","np.savetxt('test_ids.txt', test_ids, fmt='%s')\n","\n","np.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
