{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install gym gym[box2d]\n",
    "! pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# simple neural network implementation of qlearning\n",
    "import gym\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "\n",
    "# RL using OpenAI Gym: https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/\n",
    "# Deep Q-Learning: https://github.com/adventuresinML/adventures-in-ml-code/blob/master/r_learning_tensorflow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17c106d90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfQElEQVR4nO3deZxU5b3n8c+vV7DZl2CzCQaIIi5gXzaZCZJEwCyQGEmMuWBiBm/G6yuZa/Rixkm8M5qJcaKJG8Ykanv1hmsQJsTRl0FENtkRmr1tdhroFRrabqCX3/xRp/uWbL1WV5/u7/v1Otap55yq83va4tunnnqqj7k7IiISHgnxLkBERBpGwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiETs+A2sylmttvMcsxsTqyOIyLS3lgs5nGbWSKQDXwJOAysB+5w9x3NfjARkXYmVmfco4Ecd9/r7meBecC0GB1LRKRdSYrR8/YDDkXdPwyMudjOZqavb0qzSbAkunROp0NKV3Cn5JNcyk+foGvnvnRM6U7kDWHjuVdR8slhEiyZDqmdSU68DICSsiOUlx9vji6IAODudqH2WAV3ncxsNjA7XseXtmv4kKlMHPNP9Og4hH0FH7Dgbz8G4D+N/q9ce8XtpCZ1btLzn64s4f+teZCcPSv5wug59Oo1mF5pV7OvYBkL3/tvlJYWNEMvRC4uVkMlucCAqPv9g7Za7v6iu2e4e0aMapB2qGNqN64acgtdUvtRdraQzbv/TFl5cUyOVX7mBOu3/StnK8s5U3mSfj0yGHblpJgcSyRarIJ7PTDUzAabWQrwbWBRjI4lEjC+OG4OfXuNJNFSOVi4hpx9y6n9AL45B+Q88p8DR9dw6NAmSk4fICUxjb+7ehb9Lr++GQ8kcr6YDJW4e6WZ/SPwLpAIvOTu22NxLJEaV6SPplevz9I5JZ3SM8fYvOvPlJ8uqd1eUX2aovJsEi3l0w+02v98uukiLZXVp2tPeaq9kjVb/0iPngPpnNqPnp2GMnzYrRzN3051dWVzdU3kU2I2xu3ubwNvx+r5RaIlWBJDr7yZLh37kWCJ7M1bxv6Da4k+zd67bzUFeXvAakL4UmfiFz49d8CpJvdIVm1bSelhtme/TVpaL/p2GcXgvhNI7/MOuUc3N0PPRM4Xtw8nRZqX80l5ISVlByNj2zv+zNmKTz61x8cHlsTs6Lv2vcuAviNJTuzAiVMHqKo+E7NjicTkCzgNLkLTAaUZJCQk06PrFVze5yp271lCRUV5ix6/Z/cr6Zs+go/3LOX0mVMtemxpmy42HVDBLSLSSl0suPVHpkREQkbBLSISMgpuEZGQUXCLiISMgltEJGQU3CIiIaPgFhEJGQW3iEjIKLhFREJGwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCZkmXQHHzPYDp4AqoNLdM8ysB/DvwCBgPzDD3Y83rUwREanRHGfcN7v7De6eEdyfAyxx96HAkuC+iIg0k1gMlUwDMoP1TGB6DI4hItJuNTW4HfibmW00s9lBWx93PxqsHwP6NPEYIiISpalXeZ/g7rlm9hlgsZntit7o7n6x60kGQT/7QttEROTimu1iwWb2CFAK/BdgorsfNbN04AN3/1wdj9XFgkVEztHsFws2szQz61yzDtwCbAMWAbOC3WYBf2nsMURE5HyNPuM2syuBhcHdJODf3P0xM+sJvAEMBA4QmQ5YXMdz6YxbROQcFzvjbrahkqZQcIuInK/Zh0pERCQ+FNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZBRcIuIhIyCW0QkZBTcIiIho+AWEQkZBbeISMgouEVEQkbBLSISMgpuEZGQUXCLiISMgltEJGQU3CIiIaPgFhEJmTqD28xeMrN8M9sW1dbDzBab2cfBbfeg3czsaTPLMbMsMxsVy+JFRNqj+pxxvwJMOadtDrDE3YcCS4L7AFOBocEyG5jbPGWKiEiNOoPb3ZcDxec0TwMyg/VMYHpU+6sesQboZmbpzVSriIjQ+DHuPu5+NFg/BvQJ1vsBh6L2Oxy0ncfMZpvZBjPb0MgaRETapaSmPoG7u5l5Ix73IvAiQGMeLyLSXjX2jDuvZggkuM0P2nOBAVH79Q/aRESkmTQ2uBcBs4L1WcBfotpnBrNLxgIlUUMqIiLSDMz90qMUZvYnYCLQC8gDfg78X+ANYCBwAJjh7sVmZsCzRGahlAHfc/c6x7A1VCIicj53twu11xncLUHBLSJyvosFt745KSISMgpuEZGQUXCLiISMgltEJGQU3CIiIaPgFhEJGQW3iEjIKLhFREJGwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZCpM7jN7CUzyzezbVFtj5hZrpltDpZbo7Y9ZGY5ZrbbzCbHqnARkfaqPhcL/s9AKfCqu48I2h4BSt39/5yz73DgT8BooC/wHjDM3avqOIauOSkico5GX3PS3ZcDxfU8zjRgnrufcfd9QA6REBcRkWbSlDHufzSzrGAopXvQ1g84FLXP4aDtPGY228w2mNmGJtQgItLuNDa45wKfBW4AjgK/bugTuPuL7p7h7hmNrEFEpF1qVHC7e567V7l7NfB7/mM4JBcYELVr/6BNRESaSaOC28zSo+5+HaiZcbII+LaZpZrZYGAosK5pJYqISLSkunYwsz8BE4FeZnYY+Dkw0cxuABzYD9wD4O7bzewNYAdQCdxb14wSERFpmDqnA7ZIEZoOKCJynkZPBxQRkdZFwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZBRcIuIhIyCW0QkZBTcIiIho+AWEQkZBbeISMgouEVEQkbBLSISMnUGt5kNMLOlZrbDzLab2Y+C9h5mttjMPg5uuwftZmZPm1mOmWWZ2ahYd0JEpD2pzxl3JXC/uw8HxgL3mtlwYA6wxN2HAkuC+wBTiVzdfSgwG5jb7FWLiLRjdQa3ux91903B+ilgJ9APmAZkBrtlAtOD9WnAqx6xBuhmZunNXbiISHvVoDFuMxsEjATWAn3c/Wiw6RjQJ1jvBxyKetjhoO3c55ptZhvMbENDixYRac/qHdxm1gl4E/ixu5+M3ubuDnhDDuzuL7p7hrtnNORxIiLtXb2C28ySiYT26+6+IGjOqxkCCW7zg/ZcYEDUw/sHbSIi0gzqM6vEgD8CO939yahNi4BZwfos4C9R7TOD2SVjgZKoIRUREWkii4xyXGIHswnACmArUB00/5TIOPcbwEDgADDD3YuDoH8WmAKUAd9z90uOY5tZg4ZZRETaA3e3C7XXGdwtQcEtInK+iwW3vjkpIhIyCm4RkZBRcIuIhIyCW0QkZBTcIiIho+AWEQkZBbeISMgouEVEQkbBLSISMgpuEZGQUXCLiISMghtISUmhU6dORP4+lohI69bug7tDhw784he/YPHixcyZM4eRI0eSkpKiEBeRVqtd/3XATp068ctf/pLZs2eTnJxMVVUVx48fZ+vWrSxcuJD333+f3bt3U1lZGY/yRKSd0591PUfPnj351a9+xcyZM0lKSjpve1VVFfn5+WzcuJEFCxawcuVK9u7dS1VVVUuXKiLtlII7Snp6Or/+9a+ZMWMGiYmJde5fVVXFoUOH2LBhA/Pnz2ft2rUcOnRIIS4iMaXgDgwcOJCnn36ar33taw0ex675We3bt48VK1awYMEC1q5dS1FRkYZTRKTZKbiBQYMGMXfuXCZPntzkDx/dncrKSvbs2cN7773HokWL2LBhAydPntSZuIg0i4sFN+5+yYXIFduXAjuA7cCPgvZHiFy9fXOw3Br1mIeAHGA3MLkex/BYL4MHD/YlS5Z4VVWVN7eqqiovKyvzzZs3+6OPPuo33XSTd+jQwYNfSFq0aNHSqOWimVmPUE0HRgXrnYFsYDiR4P7JBfYfDmwBUoHBwB4gMZ7BPWzYMF+5cmVMQvtCIX78+HFfvXq1P/jgg56RkeHJyclxfwFo0aIlfMvFMvP86RTncPejwNFg/ZSZ7QT6XeIh04B57n4G2GdmOcBoYHVdx4qFa6+9lszMTK6//noSEmI/bT0hIYFu3boxduxYxowZQ2FhITt27ODNN99k6dKlZGdnc/bs2ZjXEUadOsF110FZGezbByUl8a4oPq67Djp0gLw8OHAg3tVIa9SgMW4zGwQsB0YA/wTcBZwENgD3u/txM3sWWOPurwWP+SPwjrvPv8Tz1r+IBrjxxht57bXX+NznPhf3L9RUV1dz7NgxNm3axMKFC1m5ciX79+9XiEcZPhwyM6G8HA4fhuPHI7fvvw8nTkSCPC8PWsHHMjGVmQnDhkFhIeTmRvq9Zg3s3h35pXb0KJw5E+8qpSV4Uz+cNLNOwDLgMXdfYGZ9gEIip/T/C0h39+/XN7jNbDYwO7h7YyP6dKlaGT9+PK+//joDBw6Me2hHq/l55+bmsnr1ahYuXMiKFSvIy8ujoqIiztXFV01wm50fzpWVkcD6+GM4eRLWr4cdO+Ds2UjAt6UfXWYmXHNNZD365+AeCfHduyN93rsXli+PhHlpKZw6FZ96JXaaFNxmlgy8Bbzr7k9eYPsg4C13H2FmDwUH/N/BtneBR9z9okMlzXnGbWZMmjSJzMxM+vbt26pC+1zuTnV1NYcOHWLp0qUsX76cDz/8kCNHjlBeXt7uZqdEB/fF1Lxcq6uhqipyVvr++/Dcc20nvKOD+0JqfgbukZ9DWRls3w6//S3k5LRMjdIyLhbcdY5xWyT5/gjsjA5tM0sPxr8Bvg5sC9YXAf9mZk8CfYGhwLom1F5vCQkJTJ48mT/84Q/07du3JQ7ZJGZGYmIigwYN4q677uLOO++krKyM7du3s2rVKtasWcO6desoKCigoqKChgxrtSU13a6qipx5f/IJbNsWOfsuKoLVq9tOaF9MdFhXVkbeaRw+HHnnUVICO3fC/v1xLVFaUJ3BDdwE/D2w1cw2B20/Be4wsxuIDJXsB+4BcPftZvYGkemDlcC97h7zU8fExESmT5/Os88+y+WXXx7rwzU7MyMlJYWUlBRuuukmxo8fT3l5OSdOnCArK4tly5axfv16srKyKCwsbNMhHpntFDmbLCyErVsjQwPZ2ZGx3rNnI2eZp0/Hu9LYiX5nUVYW6fvBg5CfHxkeKSqKjHOXlrb9MX85X5v4Ak5SUhJ33nknTzzxBL17926usloVd+fUqVPk5eWxZcsWlixZwqZNm8jJyaG4uDje5TWLa6/tyk9/2pFt246xcmUkqMrLI+Hdnr6Y+uKLV1FUtIvt2yPvJmrG8UtL412ZtLSLDZXUOY+7JRaaMM8xJSXFf/jDH3pxcXETZl+HT3V1tRcVFflHH33kL730kt95550+fPhw79q1a9znnjZ2ycjI8G9+85txryPey+OPPx73GrS0jsUbO4+7NUtJSeG+++7j5z//OZ07d453OS3KzOjRowc9evTg+uuv56677qKoqIidO3eyceNGli5dWjusUqpTNZE2JbTBnZKSwgMPPMBDDz3EZZddFu9y4qpm5kyvXr2YMGECEyZM4L777iM/P5+PPvqItWvXsnz5crKysvjkk084o0nAIqEWyuBOSUnh4Ycf5v7772/3oX2umhBPTEwkPT2d9PR0Jk+ezNmzZ8nLy2P16tWsXr2aNWvWsHPnznY57VAk7EIX3KmpqTz22GPce++9dOjQId7lhEJiYiIdO3Zk0KBBXHHFFdx+++2cOnWK3NxcVqxYwapVq9i8ebOu9iMSEqEK7rS0NJ544gl+8IMfkJycHO9yQsnMSEpKonv37nTv3p0RI0Zw9913146P/+Y3v+G9996jvLw83qWKyEWE5mLBPXr04LnnnuOee+5RaDezlJQU0tPTufnmm5k3bx7z58/nlltu0TCUSCsViuDu06cPzz//PDNnzmyRv/DXXpkZl112GVOnTmXhwoW8/vrrTJo0SQEu0sq0+hTs27cvL7zwAjNmzGjVf3ekLakJ8GnTprFo0SJefvllJkyYQGpqarxLExFaeXAPHDiQ3//+9426PqQ0nZmRlpbG7bffzl//+ldeeOEFMjIySEoK1UcjIm1Oqw3uIUOG8PLLLzNlyhQNj8SZmdGtWzdmzpzJ22+/zTPPPNNiF6YQkfO1yn9511xzDa+88goTJ05UOLQiCQkJ9O7dm3vuuYd33nmHp556ihEjRujdkEgLa3WpOGrUKDIzMxk/frxCu5UyM9LT07nvvvt45513ePzxxxk2bJgCXKSFtKpkHDNmDJmZmYwaNUohEAJmRv/+/fnJT37C4sWLefTRRxk8eLB+4YrEWKv5FzZ+/Hhee+01rrnmGoV2yJgZAwcOZM6cOXzwwQf87Gc/o3///gpwaZTExES6detGr1696NatG2lpaaSmppKYmBjv0lqNVjE9oFOnTsybN4/+/fsrtEMsISGBAQMG8PDDD/Pd736X3/3ud7z66qvk5+e36Qs/SPPo0KEDw4cP5+tf/zrTp0+nZ8+eFBQUkJ+fT35+PgUFBbVLzf2a2zNnzlBdXf2ppS2/5lpFcA8ZMkSh3UbUXI7ts5/9LI899hizZs1i7ty5vPHGGxQUFMS7PGllzIy+ffvyxS9+kRkzZjBu3Di6dOlSe3adnp7+qf3dnYqKCiorK6moqKhdjh8/zrFjxz615OfnU1xc/Knl+PHjn7ood1jDvVUEd2JiokK7DUpOTuaaa67hySef5O677+aFF15gwYIFFBYWxrs0ibMuXbowatQobrvtNqZMmcLAgQNJTk6uMweiL/EXLT09neHDh3+qraqqijNnznD69Ona29OnT1NQUMCxY8c4cuQIR48e5ejRoxQUFHDy5ElOnjxJSUkJJ0+e5NSpU1RXVzd735tDfS4W3AFYDqQG+89395+b2WBgHtAT2Aj8vbufNbNU4FXgRqAI+Ja7749R/RICKSkpjBw5kmeeeYbvf//7PP/887z11ltt5pJrUj/JyckMHTqUqVOncttttzFixIiYXgAlMTGRyy677Lw/2XD11Veft29FRQVlZWV88skntcuJEydYs2YNy5cvJycnh9zcXMrKymJWb0PU54z7DDDJ3UvNLBlYaWbvAP8EPOXu88zsBeBuYG5we9zdh5jZt4HHgW/FqH4JkZSUFEaPHs3IkSNZu3Ytzz33HO+++y4nTpyId2kSIwkJCXzmM59h3Lhx3HHHHUyYMKH2Yt6t6V12cnIyXbt2pWvXrp9q//znP8+DDz5Ibm4u2dnZrF+/nmXLlrFjxw6Ki4vjdnWpOoPbI4NANdUlB4sDk4DvBO2ZwCNEgntasA4wH3jWzMzDOpgkzarmre6ECRMYO3YsK1eu5Nlnn2Xx4sWt6h+yNE1aWhrDhw/n9ttvZ+rUqVx11VWhHBI1M8yMAQMG0L9/fyZNmsQDDzzAsWPHyMrKYuPGjaxatYotW7ZQUlJCeXl5i4yb12uM28wSiQyHDAGeA/YAJ9y95q/uHwb6Bev9gEMA7l5pZiVEhlM0sCm1zIzk5GQmTpzI+PHj+eCDD5g/fz5btmxp13+N0Mz48MMPSU1NpaqqKlQXtkhKSqJ379589atf5Rvf+Abjx48nLS2tzUwLjb66VL9+/ejbty+TJ0+moqKCoqIiNm7cyNq1a1m3bh2bN2+mpKSEioqKmAS5NeRJzawbsBD4H8Ar7j4kaB8AvOPuI8xsGzDF3Q8H2/YAY9y98Jznmg3MBhg4cOCNBw4caIbuSJiVlpbqwsZExlv37NnDrl272L17N/v27ePgwYMcOHCAEydO1F7pu7VIS0tjwoQJTJ8+nS9/+cv06dPnvA8P24uqqirKy8s5fvw4mzZtYtWqVWzcuJGtW7dSVFTU4A873f2Cb1EaFNwAZvYzoBz4Z+Dy4Kx6HPCIu082s3eD9dVmlgQcA3pfaqgkIyPDN2zY0KA6RNoDd+f06dOcOnWK0tJSjhw5wo4dO9i5cycff/xx7ayI/Pz8Fr12aFJSEldddRVTp05lxowZDBs2jM6dO4duKCTWqqurOXXqFIWFhWRlZbF8+XI2bdpEdnY2eXl5df4CbnRwm1lvoMLdT5hZR+BvRD5wnAW8GfXhZJa7P29m9wLXuvs/BB9OfsPdZ1zqGApukYarmb9cXFxMYWEh2dnZ7Nixgx07dnDkyBGKi4spKipqtpkQNXOux4wZw3e+8x3GjRvH5Zdf3maGQlqCu9de73Xnzp0sW7aMdevWcfDgQfLy8s775duU4L6OyIePiUS+Iv+Gu/9PM7uSyHTAHsBHwHfd/UwwffBfgZFAMfBtd997qWMouEWaj7tTUlJS+0WUAwcO1J6l5+Tk1M5RLi0trddb9y5dunD11VfzrW99i1tuuaX2g0ZpHmVlZezdu5ddu3axYsUKVq5cSW5uLvn5+VRXVzfPUEksKLhFYqfm37i7c/bsWQ4fPsyBAwc4ePAg2dnZ7N69m127dlFQUFD7ZZWavwD5la98henTpzN+/Hg6duwItK5pfG1JzWcXFRUVZGdnM23aNPbu3XvBH3ar+OakiMROTdCaGR06dGDIkCEMGTIEd6e6urp29kp+fj579uwhJyeH5ORkJk+eTJ8+fUI5jS+MaqYepqamcu2119KjR4+L7qvgFmmnav6uTGJiIikpKQwaNIhBgwbxhS98Id6lSR30qYKISMgouEVEQkbBLSISMgpuEZGQUXCLiISMgltEJGQU3CIiIaPgFhEJGQW3iEjIKLhFREJGwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCZk6g9vMOpjZOjPbYmbbzexfgvZXzGyfmW0OlhuCdjOzp80sx8yyzGxUjPsgItKu1OcKOGeASe5eambJwEozeyfY9oC7zz9n/6nA0GAZA8wNbkVEpBnUecbtEaXB3eRgudQVhqcBrwaPWwN0M7P0ppcqIiJQzzFuM0s0s81APrDY3dcGmx4LhkOeMrPUoK0fcCjq4YeDNhERaQb1Cm53r3L3G4D+wGgzGwE8BFwF/B3QA/jnhhzYzGab2QYz21BQUNCwqkVE2rEGzSpx9xPAUmCKux8NhkPOAC8Do4PdcoEBUQ/rH7Sd+1wvunuGu2f07t27UcWLiLRH9ZlV0tvMugXrHYEvAbtqxq3NzIDpwLbgIYuAmcHskrFAibsfjUHtIiLtUn1mlaQDmWaWSCTo33D3t8zsfTPrDRiwGfiHYP+3gVuBHKAM+F6zVy0i0o7VGdzungWMvED7pIvs78C9TS9NREQuRN+cFBEJGQW3iEjIKLhFREJGwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZBRcIuIhIyCW0QkZBTcIiIho+AWEQkZBbeISMgouEVEQkbBLSISMgpuEZGQUXCLiISMuXu8a8DMTgG7411HjPQCCuNdRAy01X5B2+2b+hUuV7h77wttSGrpSi5it7tnxLuIWDCzDW2xb221X9B2+6Z+tR0aKhERCRkFt4hIyLSW4H4x3gXEUFvtW1vtF7TdvqlfbUSr+HBSRETqr7WccYuISD3FPbjNbIqZ7TazHDObE+96GsrMXjKzfDPbFtXWw8wWm9nHwW33oN3M7Omgr1lmNip+lV+amQ0ws6VmtsPMtpvZj4L2UPfNzDqY2Toz2xL061+C9sFmtjao/9/NLCVoTw3u5wTbB8W1A3Uws0Qz+8jM3grut5V+7TezrWa22cw2BG2hfi02RVyD28wSgeeAqcBw4A4zGx7PmhrhFWDKOW1zgCXuPhRYEtyHSD+HBstsYG4L1dgYlcD97j4cGAvcG/y/CXvfzgCT3P164AZgipmNBR4HnnL3IcBx4O5g/7uB40H7U8F+rdmPgJ1R99tKvwBudvcboqb+hf212HjuHrcFGAe8G3X/IeCheNbUyH4MArZF3d8NpAfr6UTmqQP8DrjjQvu19gX4C/ClttQ34DJgEzCGyBc4koL22tcl8C4wLlhPCvazeNd+kf70JxJgk4C3AGsL/Qpq3A/0OqetzbwWG7rEe6ikH3Ao6v7hoC3s+rj70WD9GNAnWA9lf4O30SOBtbSBvgXDCZuBfGAxsAc44e6VwS7Rtdf2K9heAvRs0YLr7zfAg0B1cL8nbaNfAA78zcw2mtnsoC30r8XGai3fnGyz3N3NLLRTd8ysE/Am8GN3P2lmtdvC2jd3rwJuMLNuwELgqvhW1HRm9hUg3903mtnEOJcTCxPcPdfMPgMsNrNd0RvD+lpsrHifcecCA6Lu9w/awi7PzNIBgtv8oD1U/TWzZCKh/bq7Lwia20TfANz9BLCUyBBCNzOrOZGJrr22X8H2rkBRy1ZaLzcBXzOz/cA8IsMlvyX8/QLA3XOD23wiv2xH04Zeiw0V7+BeDwwNPvlOAb4NLIpzTc1hETArWJ9FZHy4pn1m8Kn3WKAk6q1eq2KRU+s/Ajvd/cmoTaHum5n1Ds60MbOORMbtdxIJ8G8Gu53br5r+fhN434OB09bE3R9y9/7uPojIv6P33f1OQt4vADNLM7PONevALcA2Qv5abJJ4D7IDtwLZRMYZ/3u862lE/X8CjgIVRMbS7iYyVrgE+Bh4D+gR7GtEZtHsAbYCGfGu/xL9mkBkXDEL2Bwst4a9b8B1wEdBv7YBPwvarwTWATnAn4HUoL1DcD8n2H5lvPtQjz5OBN5qK/0K+rAlWLbX5ETYX4tNWfTNSRGRkIn3UImIiDSQgltEJGQU3CIiIaPgFhEJGQW3iEjIKLhFREJGwS0iEjIKbhGRkPn/1l+v3dq4RFwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 111\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "import os\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "\n",
    "\"\"\"\n",
    "Observation Space has 8 states\n",
    "===============================\n",
    "\n",
    "1- The coordinates of the lander in x & y.\n",
    "2- Its linear velocities in x & y.\n",
    "3- Its angle.\n",
    "4- Its angular velocity.\n",
    "5- Two booleans that represent whether each leg is in contact with the ground or not.\n",
    "\n",
    "Action Space has 4 discrete actions\n",
    "===================================\n",
    "1- Do nothing.\n",
    "2- Fire left orientation engine.\n",
    "3- Fire main engine.\n",
    "4- Fire right orientation engine.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "obs = env.reset()\n",
    "image = env.render(mode='rgb_array')\n",
    "\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Methods to Save Output as GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_visuals(env, frames):\n",
    "    # Save the current game visuals\n",
    "    frame = env.render(mode='rgb_array')\n",
    "    frames.append(frame)\n",
    "\n",
    "def save_frames_as_gif(container, episode_id, frames):\n",
    "    gif = Image.fromarray(np.copy(frames[0]))\n",
    "       \n",
    "    gif_name = 'lunar_lander.{}.{}.gif'.format(episode_id, random.randint(0,2e9))\n",
    "\n",
    "    gif.save(\n",
    "        gif_name,\n",
    "        append_images=list(map(lambda im: Image.fromarray(im), frames[1:])),\n",
    "        save_all=True, duration=5, loop=0\n",
    "    )\n",
    "\n",
    "    container[episode_id] = gif_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 396, 596, 32)      2400      \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 392, 592, 32)      25600     \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 388, 588, 64)      51200     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 194, 294, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 192, 292, 64)      36864     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 192, 292, 512)     33280     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 28704768)          0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 114819076 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 114,968,420\n",
      "Trainable params: 114,968,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "N_STATES = env.observation_space.shape[0]\n",
    "N_ACTIONS = env.action_space.n\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"Construct the critic network with q-values per action as output\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(image.shape)),\n",
    "        layers.Conv2D(32, 5, activation=\"relu\", use_bias=False),\n",
    "        layers.Conv2D(32, 5, activation=\"relu\", use_bias=False),\n",
    "        layers.Conv2D(64, 5, activation=\"relu\", use_bias=False),\n",
    "        layers.MaxPool2D(2),\n",
    "        layers.Conv2D(64, 3, activation=\"relu\", use_bias=False),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(N_ACTIONS, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=optimizers.Adam(.001), loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 14:28:53.015886: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/broxoli/projects/doi-ml/rl/Lunar Lander [Images].ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 74>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/broxoli/projects/doi-ml/rl/Lunar%20Lander%20%5BImages%5D.ipynb#ch0000006?line=90'>91</a>\u001b[0m save_visuals(env, images)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/broxoli/projects/doi-ml/rl/Lunar%20Lander%20%5BImages%5D.ipynb#ch0000006?line=92'>93</a>\u001b[0m \u001b[39m# Train model based on the memory\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/broxoli/projects/doi-ml/rl/Lunar%20Lander%20%5BImages%5D.ipynb#ch0000006?line=93'>94</a>\u001b[0m \u001b[39mif\u001b[39;00m step_id\u001b[39m%\u001b[39m\u001b[39m20\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: batch_train(step_id, model, memory, score)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/broxoli/projects/doi-ml/rl/Lunar%20Lander%20%5BImages%5D.ipynb#ch0000006?line=95'>96</a>\u001b[0m \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/broxoli/projects/doi-ml/rl/Lunar%20Lander%20%5BImages%5D.ipynb#ch0000006?line=96'>97</a>\u001b[0m     episode_results \u001b[39m=\u001b[39m (step_id, score, reward, \u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m reward \u001b[39m==\u001b[39m \u001b[39m100\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/Users/broxoli/projects/doi-ml/rl/Lunar Lander [Images].ipynb Cell 9'\u001b[0m in \u001b[0;36mbatch_train\u001b[0;34m(step_id, model, memory, score, bs, log)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/broxoli/projects/doi-ml/rl/Lunar%20Lander%20%5BImages%5D.ipynb#ch0000006?line=56'>57</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/broxoli/projects/doi-ml/rl/Lunar%20Lander%20%5BImages%5D.ipynb#ch0000006?line=57'>58</a>\u001b[0m         q_s_a[idx][action] \u001b[39m=\u001b[39m reward \u001b[39m+\u001b[39m GAMMA\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mamax(q_s_a_next[idx])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/broxoli/projects/doi-ml/rl/Lunar%20Lander%20%5BImages%5D.ipynb#ch0000006?line=59'>60</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(tf\u001b[39m.\u001b[39;49mstack(X), q_s_a, batch_size\u001b[39m=\u001b[39;49mbs, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/broxoli/projects/doi-ml/rl/Lunar%20Lander%20%5BImages%5D.ipynb#ch0000006?line=61'>62</a>\u001b[0m \u001b[39mif\u001b[39;00m log \u001b[39mand\u001b[39;00m step_id\u001b[39m%\u001b[39m\u001b[39m4\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/broxoli/projects/doi-ml/rl/Lunar%20Lander%20%5BImages%5D.ipynb#ch0000006?line=62'>63</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mStep: \u001b[39m\u001b[39m'\u001b[39m, step_id, \u001b[39m'\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m'\u001b[39m, history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], \u001b[39m'\u001b[39m\u001b[39m Score: \u001b[39m\u001b[39m'\u001b[39m, score)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/training.py:1393\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1390\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1391\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1393\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1394\u001b[0m \u001b[39mif\u001b[39;00m logs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1395\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mUnexpected result of `train_function` \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1396\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m(Empty logs). Please use \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1397\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1398\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1399\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39minformation of where went wrong, or file a \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1400\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39missue/bug to `tf.keras`.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    561\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 563\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    555\u001b[0m   \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 557\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    558\u001b[0m   \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \n\u001b[1;32m   1202\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1188\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1190\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "GAMMA = 0.95\n",
    "EXPLORATION_RATE = 0.5\n",
    "\n",
    "def choose_action(model, state):\n",
    "    random_action = lambda: np.random.randint(N_ACTIONS)\n",
    "    \n",
    "    def predicted_action():\n",
    "        q_values = model(tf.expand_dims(state, 0))\n",
    "        action = tf.squeeze(tf.argmax(q_values, axis=-1))\n",
    "        return action.numpy()\n",
    "\n",
    "    # Choose between the greey move or the random move.\n",
    "    # Greedy move take the greedy approach to chose the best current action.\n",
    "    epsilon = np.random.rand()\n",
    "    action =  random_action() if epsilon <= EXPLORATION_RATE else predicted_action()\n",
    "\n",
    "    return action\n",
    "\n",
    "def obs_to_state(obs):\n",
    "    state = np.squeeze(obs)\n",
    "    return state\n",
    "\n",
    "def play(model, state):\n",
    "    return choose_action(model, state)\n",
    "\n",
    "def capped_append(memory, data, max_size=1000):\n",
    "    memory.append(data)\n",
    "    if len(memory) > max_size: memory.pop(0)\n",
    "\n",
    "def normalize_reward(reward, min=-150.0, max=150.0):\n",
    "    return (reward-min)/(max-min)\n",
    "\n",
    "def update_exploration_rate(step_id):\n",
    "    global EXPLORATION_RATE\n",
    "    if step_id > 1000: EXPLORATION_RATE = .01\n",
    "    elif step_id > 500: EXPLORATION_RATE = .05\n",
    "    elif step_id > 300: EXPLORATION_RATE = .1\n",
    "    elif step_id > 100: EXPLORATION_RATE = .2\n",
    "    elif step_id > 50: EXPLORATION_RATE = .3\n",
    "    else: EXPLORATION_RATE = .5\n",
    "\n",
    "def batch_train(step_id, model, memory, score, bs=16, log=False):\n",
    "    update_exploration_rate(step_id)\n",
    "    batch = random.sample(memory, bs) if len(memory) > bs else memory\n",
    "\n",
    "    X = tf.stack([m[0] for m in batch])\n",
    "    next_X = tf.stack([m[3] for m in batch])\n",
    "\n",
    "    q_s_a = model.predict(X)\n",
    "    q_s_a_next = model.predict(next_X)\n",
    "\n",
    "    for idx, (_, action, reward, _, done) in enumerate(batch):\n",
    "        if done:\n",
    "            q_s_a[idx][action] = reward\n",
    "        else:\n",
    "            q_s_a[idx][action] = reward + GAMMA*np.amax(q_s_a_next[idx])\n",
    "    \n",
    "    history = model.fit(tf.stack(X), q_s_a, batch_size=bs, epochs=1, verbose=0)\n",
    "\n",
    "    if log and step_id%4 == 0:\n",
    "        print('Step: ', step_id, 'Loss: ', history.history['loss'][-1], ' Score: ', score)\n",
    "    \n",
    "episodes = 3\n",
    "memory = []\n",
    "last_step_memory = []\n",
    "sims = {}\n",
    "results = []\n",
    "\n",
    "# Reset the environment to start training from scratch.\n",
    "obs = env.reset()\n",
    "\n",
    "for episode_id in range(episodes):\n",
    "    images = []\n",
    "    score = 0\n",
    "\n",
    "    for step_id in range(1000):\n",
    "        # state = obs_to_state(obs)\n",
    "        state = env.render(mode='rgb_array')\n",
    "        action = play(model, state)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        score += reward\n",
    "        next_state = env.render(mode='rgb_array')\n",
    "\n",
    "        # Save event data to memory for training later\n",
    "        # capped_append(memory, (state, action, reward, obs_to_state(obs), done))\n",
    "        capped_append(memory, (state, action, reward, next_state, done))\n",
    "        \n",
    "        # Save the current game visuals\n",
    "        save_visuals(env, images)\n",
    "\n",
    "        # Train model based on the memory\n",
    "        if step_id%20 == 0: batch_train(step_id, model, memory, score)\n",
    "\n",
    "        if done:\n",
    "            episode_results = (step_id, score, reward, True if reward == 100 else False)\n",
    "            results.append(episode_results)\n",
    "            print('Episode:', episode_id, episode_results)\n",
    "            break\n",
    "\n",
    "    obs = env.reset()\n",
    "    save_frames_as_gif(sims, episode_id, images)\n",
    "\n",
    "with open('lunar_lander.results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "model.save_weights('lunar_lander.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef4ac4ea1ec422be6b4eb59e3fa0ded4ce016edaf83e8378f1dbc473945965d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
