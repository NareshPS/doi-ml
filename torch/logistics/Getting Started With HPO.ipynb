{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Architecture Search With Ax\n",
    "\n",
    "We will follow the tutorial [HPO for PyTorch](https://ax.dev/tutorials/tune_cnn.html). We will learn to use Ax to configure and search a search space.\n",
    "\n",
    "We'll work on the problem described in the tutorial. It tunes the widths of two hidden layers, the learning rate, the dropout probability, the batch size, and the number of training epochs. The search objective is to find a good trade off between model performance and model size.\n",
    "\n",
    "Requirements for execution on cloud:\n",
    "- [] Update TOTAL_TRIALS at [Choose a Generation Strategy](#7-choose-a-generation-strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Configure Toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: Error encountered while sourcing file '/Users/broxoli/venv-tensorflow/bin/activate.fish':\n",
      "source: No such file or directory\n",
      "Cloning into 'doi-ml-toolbox'...\n",
      "remote: Enumerating objects: 42, done.\u001b[K\n",
      "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
      "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
      "remote: Total 42 (delta 12), reused 39 (delta 11), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (42/42), 892.46 KiB | 2.26 MiB/s, done.\n",
      "Resolving deltas: 100% (12/12), done.\n",
      "source: Error encountered while sourcing file '/Users/broxoli/venv-tensorflow/bin/activate.fish':\n",
      "source: No such file or directory\n",
      "mv: rename doi-ml-toolbox/torch/toolbox to ./toolbox: Directory not empty\n",
      "source: Error encountered while sourcing file '/Users/broxoli/venv-tensorflow/bin/activate.fish':\n",
      "source: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/NareshPS/doi-ml-toolbox.git\n",
    "! mv doi-ml-toolbox/torch/toolbox .\n",
    "! rm -rf doi-ml-toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "from ax.utils.tutorials.cnn_utils import load_mnist, train, evaluate, CNN\n",
    "from toolbox import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Device Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "device = utils.get_device()\n",
    "\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Create Dataloaders for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 7530582.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 36464688.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2324087.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 9028686.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader = load_mnist(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define Optimization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(parameters):\n",
    "    net = CNN()\n",
    "    net = train(net=net, train_loader=train_loader, parameters=parameters, dtype=torch.float, device=device)\n",
    "    return evaluate(\n",
    "        net=net,\n",
    "        data_loader=valid_loader,\n",
    "        dtype=torch.float,\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.104"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_evaluate(dict(lr=0.01, momentum=0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Optimization Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 08-01 14:35:49] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter lr. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 08-01 14:35:49] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter momentum. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 08-01 14:35:49] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='lr', parameter_type=FLOAT, range=[1e-06, 0.4], log_scale=True), RangeParameter(name='momentum', parameter_type=FLOAT, range=[0.0, 1.0])], parameter_constraints=[]).\n",
      "[INFO 08-01 14:35:49] ax.modelbridge.dispatch_utils: Using Models.GPEI since there are more ordered parameters than there are categories for the unordered categorical parameters.\n",
      "[INFO 08-01 14:35:49] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=2 num_trials=None use_batch_trials=False\n",
      "[INFO 08-01 14:35:49] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=5\n",
      "[INFO 08-01 14:35:49] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=5\n",
      "[INFO 08-01 14:35:49] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 trials, GPEI for subsequent trials]). Iterations after 5 will take longer to generate due to model-fitting.\n",
      "[INFO 08-01 14:35:49] ax.service.managed_loop: Started full optimization with 20 steps.\n",
      "[INFO 08-01 14:35:49] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 08-01 14:35:51] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 08-01 14:35:53] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 08-01 14:35:54] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 08-01 14:35:56] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 08-01 14:35:58] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 08-01 14:36:00] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 08-01 14:36:01] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 08-01 14:36:03] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 08-01 14:36:05] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 08-01 14:36:07] ax.service.managed_loop: Running optimization trial 11...\n",
      "[INFO 08-01 14:36:09] ax.service.managed_loop: Running optimization trial 12...\n",
      "[INFO 08-01 14:36:11] ax.service.managed_loop: Running optimization trial 13...\n",
      "[INFO 08-01 14:36:13] ax.service.managed_loop: Running optimization trial 14...\n",
      "[INFO 08-01 14:36:15] ax.service.managed_loop: Running optimization trial 15...\n",
      "[INFO 08-01 14:36:17] ax.service.managed_loop: Running optimization trial 16...\n",
      "[INFO 08-01 14:36:19] ax.service.managed_loop: Running optimization trial 17...\n",
      "[INFO 08-01 14:36:20] ax.service.managed_loop: Running optimization trial 18...\n",
      "[INFO 08-01 14:36:22] ax.service.managed_loop: Running optimization trial 19...\n",
      "[INFO 08-01 14:36:24] ax.service.managed_loop: Running optimization trial 20...\n",
      "/Users/broxoli/venv-torch/lib/python3.9/site-packages/ax/utils/stats/model_fit_stats.py:132: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in divide\n",
      "\n",
      "/Users/broxoli/venv-torch/lib/python3.9/site-packages/ax/utils/stats/model_fit_stats.py:143: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in divide\n",
      "\n",
      "/Users/broxoli/venv-torch/lib/python3.9/site-packages/ax/utils/stats/model_fit_stats.py:150: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "[WARNING 08-01 14:36:26] ax.modelbridge.cross_validation: Metric accuracy was unable to be reliably fit.\n",
      "[WARNING 08-01 14:36:26] ax.service.utils.best_point: Model fit is poor; falling back on raw data for best point.\n",
      "[WARNING 08-01 14:36:26] ax.service.utils.best_point: Model fit is poor and data on objective metric accuracy is noisy; interpret best points results carefully.\n"
     ]
    }
   ],
   "source": [
    "best_parameters, values, experiment, model = optimize(\n",
    "    parameters=[\n",
    "        {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [1e-6, 0.4], \"log_scale\": True},\n",
    "        {\"name\": \"momentum\", \"type\": \"range\", \"bounds\": [0.0, 1.0]},\n",
    "    ],\n",
    "    evaluation_function=train_and_evaluate,\n",
    "    objective_name='accuracy',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
