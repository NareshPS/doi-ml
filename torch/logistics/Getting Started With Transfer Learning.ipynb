{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuse Knowledge with Transfer Learning\n",
    "\n",
    "We will improve over the TinyVGG model in [Getting Started With Custom Datasets](Getting%20Started%20With%20Custom%20Datasets.ipynb) using transfer learning. Below is the breakdown of this notebook:\n",
    "\n",
    "- [Data Preparation](#data-preparation).\n",
    "  - [Procurement](#procurement)\n",
    "- [Dataset Creation](#create-datasets-and-dataloaders-data_setuppy)\n",
    "- [TinyVGG Model](#tinyvgg-module_builderpy)\n",
    "- [Training Functions](#training-functions-enginepy)\n",
    "- [Saving and Loading Models](#saving-and-loading-models-and-other-utility-functions-utilspy)\n",
    "- [Training and Evaluation](#train-evaluate-and-save-the-model-trainpy)\n",
    "\n",
    "We'll follow the [PyTorch Going Modular](https://www.learnpytorch.io/05_pytorch_going_modular) tutorial by [@mrdbourke](https://github.com/mrdbourke/pytorch-deep-learning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "module_path = Path('./modularization_example')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procurement\n",
    "\n",
    "We will download the [Food101](https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/broxoli/.datasets/pizza_steak_sushi directory exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# 1. Setup path to data folder\n",
    "data_path = Path(os.path.expanduser(\"~/.datasets/\"))\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "train_path = image_path / 'train'\n",
    "test_path = image_path / 'test'\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it... \n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 2. Download pizza, steak, sushi data\n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        print(\"Downloading pizza, steak, sushi data...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    # 3. Unzip pizza, steak, sushi data\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        print(\"Unzipping pizza, steak, sushi data...\") \n",
    "        zip_ref.extractall(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
