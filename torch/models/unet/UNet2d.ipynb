{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type (var_name))                  Output Shape         Param #              Trainable\n",
       "====================================================================================================\n",
       "UNet (UNet)                              [16, 1, 224, 224]    --                   True\n",
       "├─Sequential (encoder1)                  [16, 32, 224, 224]   --                   True\n",
       "│    └─Conv2d (enc1conv1)                [16, 32, 224, 224]   288                  True\n",
       "│    └─BatchNorm2d (enc1norm1)           [16, 32, 224, 224]   64                   True\n",
       "│    └─ReLU (enc1relu1)                  [16, 32, 224, 224]   --                   --\n",
       "│    └─Conv2d (enc1conv2)                [16, 32, 224, 224]   9,216                True\n",
       "│    └─BatchNorm2d (enc1norm2)           [16, 32, 224, 224]   64                   True\n",
       "│    └─ReLU (enc1relu2)                  [16, 32, 224, 224]   --                   --\n",
       "├─MaxPool2d (pool1)                      [16, 32, 112, 112]   --                   --\n",
       "├─Sequential (encoder2)                  [16, 64, 112, 112]   --                   True\n",
       "│    └─Conv2d (enc2conv1)                [16, 64, 112, 112]   18,432               True\n",
       "│    └─BatchNorm2d (enc2norm1)           [16, 64, 112, 112]   128                  True\n",
       "│    └─ReLU (enc2relu1)                  [16, 64, 112, 112]   --                   --\n",
       "│    └─Conv2d (enc2conv2)                [16, 64, 112, 112]   36,864               True\n",
       "│    └─BatchNorm2d (enc2norm2)           [16, 64, 112, 112]   128                  True\n",
       "│    └─ReLU (enc2relu2)                  [16, 64, 112, 112]   --                   --\n",
       "├─MaxPool2d (pool2)                      [16, 64, 56, 56]     --                   --\n",
       "├─Sequential (encoder3)                  [16, 128, 56, 56]    --                   True\n",
       "│    └─Conv2d (enc3conv1)                [16, 128, 56, 56]    73,728               True\n",
       "│    └─BatchNorm2d (enc3norm1)           [16, 128, 56, 56]    256                  True\n",
       "│    └─ReLU (enc3relu1)                  [16, 128, 56, 56]    --                   --\n",
       "│    └─Conv2d (enc3conv2)                [16, 128, 56, 56]    147,456              True\n",
       "│    └─BatchNorm2d (enc3norm2)           [16, 128, 56, 56]    256                  True\n",
       "│    └─ReLU (enc3relu2)                  [16, 128, 56, 56]    --                   --\n",
       "├─MaxPool2d (pool3)                      [16, 128, 28, 28]    --                   --\n",
       "├─Sequential (encoder4)                  [16, 256, 28, 28]    --                   True\n",
       "│    └─Conv2d (enc4conv1)                [16, 256, 28, 28]    294,912              True\n",
       "│    └─BatchNorm2d (enc4norm1)           [16, 256, 28, 28]    512                  True\n",
       "│    └─ReLU (enc4relu1)                  [16, 256, 28, 28]    --                   --\n",
       "│    └─Conv2d (enc4conv2)                [16, 256, 28, 28]    589,824              True\n",
       "│    └─BatchNorm2d (enc4norm2)           [16, 256, 28, 28]    512                  True\n",
       "│    └─ReLU (enc4relu2)                  [16, 256, 28, 28]    --                   --\n",
       "├─MaxPool2d (pool4)                      [16, 256, 14, 14]    --                   --\n",
       "├─Sequential (bottleneck)                [16, 512, 14, 14]    --                   True\n",
       "│    └─Conv2d (bottleneckconv1)          [16, 512, 14, 14]    1,179,648            True\n",
       "│    └─BatchNorm2d (bottlenecknorm1)     [16, 512, 14, 14]    1,024                True\n",
       "│    └─ReLU (bottleneckrelu1)            [16, 512, 14, 14]    --                   --\n",
       "│    └─Conv2d (bottleneckconv2)          [16, 512, 14, 14]    2,359,296            True\n",
       "│    └─BatchNorm2d (bottlenecknorm2)     [16, 512, 14, 14]    1,024                True\n",
       "│    └─ReLU (bottleneckrelu2)            [16, 512, 14, 14]    --                   --\n",
       "├─ConvTranspose2d (upconv4)              [16, 256, 28, 28]    524,544              True\n",
       "├─Sequential (decoder4)                  [16, 256, 28, 28]    --                   True\n",
       "│    └─Conv2d (dec4conv1)                [16, 256, 28, 28]    1,179,648            True\n",
       "│    └─BatchNorm2d (dec4norm1)           [16, 256, 28, 28]    512                  True\n",
       "│    └─ReLU (dec4relu1)                  [16, 256, 28, 28]    --                   --\n",
       "│    └─Conv2d (dec4conv2)                [16, 256, 28, 28]    589,824              True\n",
       "│    └─BatchNorm2d (dec4norm2)           [16, 256, 28, 28]    512                  True\n",
       "│    └─ReLU (dec4relu2)                  [16, 256, 28, 28]    --                   --\n",
       "├─ConvTranspose2d (upconv3)              [16, 128, 56, 56]    131,200              True\n",
       "├─Sequential (decoder3)                  [16, 128, 56, 56]    --                   True\n",
       "│    └─Conv2d (dec3conv1)                [16, 128, 56, 56]    294,912              True\n",
       "│    └─BatchNorm2d (dec3norm1)           [16, 128, 56, 56]    256                  True\n",
       "│    └─ReLU (dec3relu1)                  [16, 128, 56, 56]    --                   --\n",
       "│    └─Conv2d (dec3conv2)                [16, 128, 56, 56]    147,456              True\n",
       "│    └─BatchNorm2d (dec3norm2)           [16, 128, 56, 56]    256                  True\n",
       "│    └─ReLU (dec3relu2)                  [16, 128, 56, 56]    --                   --\n",
       "├─ConvTranspose2d (upconv2)              [16, 64, 112, 112]   32,832               True\n",
       "├─Sequential (decoder2)                  [16, 64, 112, 112]   --                   True\n",
       "│    └─Conv2d (dec2conv1)                [16, 64, 112, 112]   73,728               True\n",
       "│    └─BatchNorm2d (dec2norm1)           [16, 64, 112, 112]   128                  True\n",
       "│    └─ReLU (dec2relu1)                  [16, 64, 112, 112]   --                   --\n",
       "│    └─Conv2d (dec2conv2)                [16, 64, 112, 112]   36,864               True\n",
       "│    └─BatchNorm2d (dec2norm2)           [16, 64, 112, 112]   128                  True\n",
       "│    └─ReLU (dec2relu2)                  [16, 64, 112, 112]   --                   --\n",
       "├─ConvTranspose2d (upconv1)              [16, 32, 224, 224]   8,224                True\n",
       "├─Sequential (decoder1)                  [16, 32, 224, 224]   --                   True\n",
       "│    └─Conv2d (dec1conv1)                [16, 32, 224, 224]   18,432               True\n",
       "│    └─BatchNorm2d (dec1norm1)           [16, 32, 224, 224]   64                   True\n",
       "│    └─ReLU (dec1relu1)                  [16, 32, 224, 224]   --                   --\n",
       "│    └─Conv2d (dec1conv2)                [16, 32, 224, 224]   9,216                True\n",
       "│    └─BatchNorm2d (dec1norm2)           [16, 32, 224, 224]   64                   True\n",
       "│    └─ReLU (dec1relu2)                  [16, 32, 224, 224]   --                   --\n",
       "├─Conv2d (output)                        [16, 1, 224, 224]    33                   True\n",
       "====================================================================================================\n",
       "Total params: 7,762,465\n",
       "Trainable params: 7,762,465\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 167.19\n",
       "====================================================================================================\n",
       "Input size (MB): 3.21\n",
       "Forward/backward pass size (MB): 3525.97\n",
       "Params size (MB): 31.05\n",
       "Estimated Total Size (MB): 3560.23\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: https://github.com/mateuszbuda/brain-segmentation-pytorch/blob/master/unet.py\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import OrderedDict\n",
    "from torchinfo import summary\n",
    "from functools import reduce\n",
    "from itertools import accumulate\n",
    "from torchview import draw_graph\n",
    "\n",
    "class UNet2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, blocks=[32, 64, 128, 256]):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.blocks = blocks\n",
    "\n",
    "        # Encoder Modules\n",
    "        in_features = in_channels\n",
    "        for enc_id, block in enumerate(blocks, start=1):\n",
    "            setattr(\n",
    "                self, f'encoder{enc_id}',\n",
    "                UNet._block(in_features, block, name=f'enc{enc_id}')\n",
    "            )\n",
    "            in_features = block\n",
    "\n",
    "        # Pooling Layers\n",
    "        for pool_id, _ in enumerate(blocks, start=1):\n",
    "            setattr(\n",
    "                self, f'pool{pool_id}',\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "\n",
    "        # Bottleneck Module\n",
    "        self.bottleneck = UNet._block(blocks[-1], blocks[-1]*2, name=\"bottleneck\")\n",
    "\n",
    "        # Upconv Layers\n",
    "        for up_id, block in enumerate(blocks, start=1):\n",
    "            setattr(\n",
    "                self, f'upconv{up_id}',\n",
    "                nn.ConvTranspose2d(\n",
    "                    block*2, block, kernel_size=2, stride=2,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Decoder Modules\n",
    "        for dec_id, block in enumerate(blocks, start=1):\n",
    "            setattr(\n",
    "                self, f'decoder{dec_id}',\n",
    "                UNet._block(block*2, block, name=f'dec{dec_id}')\n",
    "            )\n",
    "\n",
    "        # Output Layer\n",
    "        self.output = nn.Conv2d(\n",
    "            in_channels=blocks[0], out_channels=out_channels, kernel_size=1,\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 1. Encoder Leg\n",
    "        block_encodings = [None]\n",
    "        for block_id, _ in enumerate(self.blocks, start=1):\n",
    "            encoder = getattr(self, f'encoder{block_id}')\n",
    "            pool = getattr(self, f'pool{block_id}')\n",
    "\n",
    "            x = encoder(x)\n",
    "            block_encodings.append(x)\n",
    "            x = pool(x)\n",
    "\n",
    "        # 2. Apply Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # 3. Decoder Leg\n",
    "        for block_id in range(len(self.blocks), 0, -1):\n",
    "            upconv = getattr(self, f'upconv{block_id}')\n",
    "            decoder = getattr(self, f'decoder{block_id}')\n",
    "            block_encoding = block_encodings[block_id]\n",
    "\n",
    "            x = upconv(x)\n",
    "            x = torch.cat((block_encoding, x), dim=1)\n",
    "            x = decoder(x)\n",
    "\n",
    "        # 4. Output\n",
    "        output = self.output(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "model = UNet2d(in_channels=1)\n",
    "\n",
    "summary(\n",
    "    model=model, \n",
    "    input_size=(16, 1, 224, 224),\n",
    "    # input_size=(4, 1, 512, 512),\n",
    "    col_names=[\"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"],\n",
    ")\n",
    "\n",
    "# graph = draw_graph(\n",
    "#     model, \n",
    "#     input_size=(1, 1, 224, 224), \n",
    "#     # expand_nested=True\n",
    "# )\n",
    "\n",
    "# # View Model Architecture\n",
    "# graph.visual_graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
