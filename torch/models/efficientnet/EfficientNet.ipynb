{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Conv1dNormActivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Conv1dNormActivation(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels, out_channels, kernel_size,\n",
    "        norm_layer=nn.BatchNorm1d,\n",
    "        activation_layer=nn.ReLU,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, **kwargs)\n",
    "        self.norm = norm_layer(out_channels) if norm_layer else None\n",
    "        self.activation = activation_layer() if activation_layer else None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x) if self.norm else x\n",
    "        x = self.activation(x) if self.activation else x\n",
    "        return x\n",
    "\n",
    "# in_channels, out_channels = 144, 64\n",
    "# x = torch.randn(1, in_channels, 10)\n",
    "# l = Conv1dNormActivation(\n",
    "#     in_channels, out_channels,\n",
    "#     kernel_size=3, padding='same',\n",
    "# )\n",
    "\n",
    "# print(summary(\n",
    "#     model=l, \n",
    "#     input_data=x,\n",
    "#     col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#     col_width=20,\n",
    "#     row_settings=[\"var_names\"]\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. ChannelSeBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
      "========================================================================================================================\n",
      "ChannelSeBlock (ChannelSeBlock)          [1, 144, 10, 10]     [1, 144, 10, 10]     --                   True\n",
      "├─AdaptiveAvgPool2d (pool)               [1, 144, 10, 10]     [1, 144, 1, 1]       --                   --\n",
      "├─Conv2dNormActivation (conv1)           [1, 144, 1, 1]       [1, 6, 1, 1]         --                   True\n",
      "│    └─Conv2d (0)                        [1, 144, 1, 1]       [1, 6, 1, 1]         870                  True\n",
      "│    └─ReLU (1)                          [1, 6, 1, 1]         [1, 6, 1, 1]         --                   --\n",
      "├─Conv2dNormActivation (conv2)           [1, 6, 1, 1]         [1, 144, 1, 1]       --                   True\n",
      "│    └─Conv2d (0)                        [1, 6, 1, 1]         [1, 144, 1, 1]       864                  True\n",
      "├─Sigmoid (sigmoid)                      [1, 144, 1, 1]       [1, 144, 1, 1]       --                   --\n",
      "========================================================================================================================\n",
      "Total params: 1,734\n",
      "Trainable params: 1,734\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "========================================================================================================================\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.07\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "class ChannelSeBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels, squeeze_channels,\n",
    "        activation_layer=nn.ReLU,\n",
    "        conv_block=ops.Conv2dNormActivation,\n",
    "        pool_block=nn.AdaptiveAvgPool2d,\n",
    "    ):\n",
    "        \"\"\"ChannelSeBlock is a Squeeze-And-Excitation block.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): The number of input channels.\n",
    "            squeeze_channels (int): The number of channels to squeeze to.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.pool = pool_block(1)\n",
    "        self.conv1 = conv_block(\n",
    "            in_channels, squeeze_channels, 1,\n",
    "            activation_layer=activation_layer,\n",
    "            norm_layer=None, bias=False,\n",
    "        )\n",
    "        self.conv2 = conv_block(\n",
    "            squeeze_channels, in_channels, 1,\n",
    "            norm_layer=None, activation_layer=None, bias=False,\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        inp = x\n",
    "\n",
    "        # 1. (...) -> (..., in_channels, 1, 1)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # 2. -> (..., squeeze_channels, 1, 1)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        # 3. -> (..., in_channels, 1, 1)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # 4. Scale\n",
    "        x = self.sigmoid(x)\n",
    "        x = inp * x\n",
    "\n",
    "        return x\n",
    "\n",
    "# in_channels = 144\n",
    "# x = torch.randn(1, in_channels, 10, 10)\n",
    "# l = ChannelSeBlock(in_channels, squeeze_channels=6)\n",
    "\n",
    "# print(summary(\n",
    "#     model=l, \n",
    "#     input_data=x,\n",
    "#     col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#     col_width=20,\n",
    "#     row_settings=[\"var_names\"]\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. SpatialSeBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
      "========================================================================================================================\n",
      "SpatialSeBlock (SpatialSeBlock)          [1, 144, 10, 10]     [1, 144, 10, 10]     --                   True\n",
      "├─Conv2dNormActivation (conv)            [1, 144, 10, 10]     [1, 1, 10, 10]       --                   True\n",
      "│    └─Conv2d (0)                        [1, 144, 10, 10]     [1, 1, 10, 10]       145                  True\n",
      "├─Sigmoid (sigmoid)                      [1, 1, 10, 10]       [1, 1, 10, 10]       --                   --\n",
      "========================================================================================================================\n",
      "Total params: 145\n",
      "Trainable params: 145\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.01\n",
      "========================================================================================================================\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.06\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "class SpatialSeBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels, squeeze_channels,\n",
    "        conv_block=ops.Conv2dNormActivation,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"SpatialSeBlock is a spatial Squeeze-And-Excitation.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): The number of input channels.\n",
    "            squeeze_channels (int): The number of channels to squeeze to.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = conv_block(\n",
    "            in_channels, 1, 1,\n",
    "            norm_layer=None, activation_layer=None, bias=None,\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. Save input -> (..., in_channels, H, W)\n",
    "        inp = x\n",
    "\n",
    "        # 2. -> (..., 1, H, W)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # 3. Scale\n",
    "        x = self.sigmoid(x)\n",
    "        x = inp * x\n",
    "\n",
    "        return x\n",
    "\n",
    "# in_channels = 144\n",
    "# x = torch.randn(1, in_channels, 10, 10)\n",
    "# l = SpatialSeBlock(in_channels, squeeze_channels=6)\n",
    "\n",
    "# print(summary(\n",
    "#     model=l, \n",
    "#     input_data=x,\n",
    "#     col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#     col_width=20,\n",
    "#     row_settings=[\"var_names\"]\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. SpatialChannelSeBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================================================\n",
      "Layer (type (var_name))                            Input Shape          Output Shape         Param #              Trainable\n",
      "==================================================================================================================================\n",
      "SpatialChannelSeBlock (SpatialChannelSeBlock)      [1, 144, 10, 10]     [1, 144, 10, 10]     --                   True\n",
      "├─SpatialSeBlock (spatial_se)                      [1, 144, 10, 10]     [1, 144, 10, 10]     --                   True\n",
      "│    └─Conv2dNormActivation (conv)                 [1, 144, 10, 10]     [1, 1, 10, 10]       --                   True\n",
      "│    │    └─Conv2d (0)                             [1, 144, 10, 10]     [1, 1, 10, 10]       145                  True\n",
      "│    └─Sigmoid (sigmoid)                           [1, 1, 10, 10]       [1, 1, 10, 10]       --                   --\n",
      "├─ChannelSeBlock (channel_se)                      [1, 144, 10, 10]     [1, 144, 10, 10]     --                   True\n",
      "│    └─AdaptiveAvgPool2d (pool)                    [1, 144, 10, 10]     [1, 144, 1, 1]       --                   --\n",
      "│    └─Conv2dNormActivation (conv1)                [1, 144, 1, 1]       [1, 6, 1, 1]         --                   True\n",
      "│    │    └─Conv2d (0)                             [1, 144, 1, 1]       [1, 6, 1, 1]         870                  True\n",
      "│    │    └─ReLU (1)                               [1, 6, 1, 1]         [1, 6, 1, 1]         --                   --\n",
      "│    └─Conv2dNormActivation (conv2)                [1, 6, 1, 1]         [1, 144, 1, 1]       --                   True\n",
      "│    │    └─Conv2d (0)                             [1, 6, 1, 1]         [1, 144, 1, 1]       864                  True\n",
      "│    └─Sigmoid (sigmoid)                           [1, 144, 1, 1]       [1, 144, 1, 1]       --                   --\n",
      "==================================================================================================================================\n",
      "Total params: 1,879\n",
      "Trainable params: 1,879\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.02\n",
      "==================================================================================================================================\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.07\n",
      "==================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "class SpatialChannelSeBlock(nn.Module):\n",
    "    def __init__(self, in_channels, squeeze_channels, **kwargs):\n",
    "        \"\"\"SpatialChannelSeBlock is a Squeeze-And-Excitation block\n",
    "        which combines spatial and channel squeeze-and-excitation.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): The number of input channels.\n",
    "            squeeze_channels (int): The number of channels to squeeze to.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.spatial_se = SpatialSeBlock(\n",
    "            in_channels=in_channels, squeeze_channels=squeeze_channels,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.channel_se = ChannelSeBlock(\n",
    "            in_channels=in_channels, squeeze_channels=squeeze_channels,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. Spatial scaling\n",
    "        spatial_x = self.spatial_se(x)\n",
    "\n",
    "        # 2. Channel scaling\n",
    "        channel_x = self.channel_se(x)\n",
    "\n",
    "        # 3. Combine spatial and channel scaling results\n",
    "        x = spatial_x + channel_x\n",
    "\n",
    "        return x\n",
    "\n",
    "# in_channels = 144\n",
    "# x = torch.randn(1, in_channels, 10, 10)\n",
    "# l = SpatialChannelSeBlock(in_channels, squeeze_channels=6)\n",
    "\n",
    "# print(summary(\n",
    "#     model=l, \n",
    "#     input_data=x,\n",
    "#     col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#     col_width=20,\n",
    "#     row_settings=[\"var_names\"]\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. HSeBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
      "========================================================================================================================\n",
      "HSeBlock (HSeBlock)                      [1, 144, 10, 10]     [1, 144, 10, 10]     --                   True\n",
      "├─Conv2dNormActivation (conv)            [1, 144, 10, 1]      [1, 1, 10, 1]        --                   True\n",
      "│    └─Conv2d (0)                        [1, 144, 10, 1]      [1, 1, 10, 1]        145                  True\n",
      "├─Sigmoid (sigmoid)                      [1, 1, 10, 1]        [1, 1, 10, 1]        --                   --\n",
      "========================================================================================================================\n",
      "Total params: 145\n",
      "Trainable params: 145\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "========================================================================================================================\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.06\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "class HSeBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels, squeeze_channels,\n",
    "        activation_layer=nn.ReLU,\n",
    "        conv_block=ops.Conv2dNormActivation,\n",
    "        pool_block=nn.AdaptiveAvgPool2d,\n",
    "    ):\n",
    "        \"\"\"HSeBlock is a Squeeze-And-Excitation block.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): The number of input channels.\n",
    "            squeeze_channels (int): The number of channels to squeeze to.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = conv_block(\n",
    "            in_channels, 1, 1,\n",
    "            norm_layer=None, activation_layer=None, bias=None,\n",
    "        )\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        inp = x\n",
    "\n",
    "        # 1. -> (..., in_channels, H, 1)\n",
    "        x = x.mean(dim=-1, keepdim=True)\n",
    "\n",
    "        # 2. -> (..., 1, H, 1)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # 3. Scale\n",
    "        x = self.sigmoid(x)\n",
    "        x = inp * x\n",
    "\n",
    "        return x\n",
    "\n",
    "# in_channels = 144\n",
    "# x = torch.randn(1, in_channels, 10, 10)\n",
    "# l = HSeBlock(in_channels, squeeze_channels=6)\n",
    "\n",
    "# print(summary(\n",
    "#     model=l, \n",
    "#     input_data=x,\n",
    "#     col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#     col_width=20,\n",
    "#     row_settings=[\"var_names\"]\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
      "========================================================================================================================\n",
      "HBADeSeBlock (HBADeSeBlock)              [1, 144, 10, 10]     [1, 144, 10, 10]     --                   True\n",
      "├─ConvTranspose2d (deconv)               [1, 144, 10, 1]      [1, 6, 20, 1]        2,598                True\n",
      "├─ReLU (activation)                      [1, 6, 20, 1]        [1, 6, 20, 1]        --                   --\n",
      "├─Conv2dNormActivation (conv)            [1, 6, 20, 1]        [1, 144, 10, 1]      --                   True\n",
      "│    └─Conv2d (0)                        [1, 6, 20, 1]        [1, 144, 10, 1]      2,736                True\n",
      "========================================================================================================================\n",
      "Total params: 5,334\n",
      "Trainable params: 5,334\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.08\n",
      "========================================================================================================================\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.09\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.ops as ops\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "class HBADeSeBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels, squeeze_channels,\n",
    "        activation_layer=nn.ReLU,\n",
    "        conv_block=ops.Conv2dNormActivation,\n",
    "        pool_block=nn.AdaptiveAvgPool2d,\n",
    "    ):\n",
    "        \"\"\"HBADeSeBlock is a FusedMBConv block with Squeeze-And-Excitation.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): The number of input channels.\n",
    "            squeeze_channels (int): The number of channels to squeeze to.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.deconv = nn.ConvTranspose2d(\n",
    "            in_channels, squeeze_channels, (3, 1),\n",
    "            stride=(2, 1), padding=(1, 0), output_padding=(1, 0),\n",
    "        )\n",
    "        self.activation = activation_layer()\n",
    "        self.conv = conv_block(\n",
    "            squeeze_channels, in_channels, (3, 1),\n",
    "            stride=(2, 1), padding=(1, 0),\n",
    "            norm_layer=None, activation_layer=None,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        inp = x\n",
    "\n",
    "        # 1. (...) -> (..., in_channels, H, 1)\n",
    "        x = x.mean(dim=-1, keepdim=True)\n",
    "\n",
    "        # 2. -> (..., squeeze_channels, 2H, 1)\n",
    "        x = self.deconv(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # 3. -> (..., in_channels, H, 1)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # 4. Scale\n",
    "        x = inp * x.sigmoid()\n",
    "\n",
    "        return x\n",
    "\n",
    "# in_channels = 144\n",
    "# x = torch.randn(1, in_channels, 10, 10)\n",
    "# l = HBADeSeBlock(in_channels, squeeze_channels=6)\n",
    "\n",
    "# print(summary(\n",
    "#     model=l, \n",
    "#     input_data=x,\n",
    "#     col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#     col_width=20,\n",
    "#     row_settings=[\"var_names\"]\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
      "========================================================================================================================\n",
      "HBAChannelHSeBlock (HBAChannelHSeBlock)  [1, 144, 10, 10]     [1, 144, 10, 10]     --                   True\n",
      "├─ChannelSeBlock (channel_se)            [1, 144, 10, 10]     [1, 144, 10, 10]     --                   True\n",
      "│    └─AdaptiveAvgPool2d (pool)          [1, 144, 10, 10]     [1, 144, 1, 1]       --                   --\n",
      "│    └─Conv2dNormActivation (conv1)      [1, 144, 1, 1]       [1, 6, 1, 1]         --                   True\n",
      "│    │    └─Conv2d (0)                   [1, 144, 1, 1]       [1, 6, 1, 1]         870                  True\n",
      "│    │    └─ReLU (1)                     [1, 6, 1, 1]         [1, 6, 1, 1]         --                   --\n",
      "│    └─Conv2dNormActivation (conv2)      [1, 6, 1, 1]         [1, 144, 1, 1]       --                   True\n",
      "│    │    └─Conv2d (0)                   [1, 6, 1, 1]         [1, 144, 1, 1]       864                  True\n",
      "│    └─Sigmoid (sigmoid)                 [1, 144, 1, 1]       [1, 144, 1, 1]       --                   --\n",
      "├─HSeBlock (h_se)                        [1, 144, 10, 10]     [1, 144, 10, 10]     --                   True\n",
      "│    └─Conv2dNormActivation (conv)       [1, 144, 10, 1]      [1, 1, 10, 1]        --                   True\n",
      "│    │    └─Conv2d (0)                   [1, 144, 10, 1]      [1, 1, 10, 1]        145                  True\n",
      "│    └─Sigmoid (sigmoid)                 [1, 1, 10, 1]        [1, 1, 10, 1]        --                   --\n",
      "========================================================================================================================\n",
      "Total params: 1,879\n",
      "Trainable params: 1,879\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "========================================================================================================================\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.07\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "class HBAChannelHSeBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels, squeeze_channels,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"HBAChannelHSeBlock is a FusedMBConv block with Squeeze-And-Excitation.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): The number of input channels.\n",
    "            squeeze_channels (int): The number of channels to squeeze to.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.channel_se = ChannelSeBlock(\n",
    "            in_channels=in_channels, squeeze_channels=squeeze_channels,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.h_se = HSeBlock(\n",
    "            in_channels=in_channels, squeeze_channels=squeeze_channels,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. Channel scaling\n",
    "        channel_x = self.channel_se(x)\n",
    "\n",
    "        # 2. H scaling\n",
    "        h_x = self.h_se(x)\n",
    "\n",
    "        # 3. Combine spatial and channel scaling results\n",
    "        x = channel_x + h_x\n",
    "\n",
    "        return x\n",
    "\n",
    "# in_channels = 144\n",
    "# x = torch.randn(1, in_channels, 10, 10)\n",
    "# l = HBAChannelHSeBlock(in_channels, squeeze_channels=6)\n",
    "\n",
    "# print(summary(\n",
    "#     model=l, \n",
    "#     input_data=x,\n",
    "#     col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#     col_width=20,\n",
    "#     row_settings=[\"var_names\"]\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. MBConv\n",
    "\n",
    "EfficientNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.ops as ops\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels, out_channels,\n",
    "        bottleneck=4, kernel_size=3, stride=1, padding='same', squeeze_ratio=4,\n",
    "        activation_layer=nn.SiLU,\n",
    "        se_block=ChannelSeBlock,\n",
    "        conv_block=ops.Conv2dNormActivation,\n",
    "        pool_block=nn.AdaptiveAvgPool2d,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"EfficientNetBlock is a MBConv block with SEBlock.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): The number of input channels.\n",
    "            out_channels (int): The number of output channels.\n",
    "            bottleneck (int, optional): The size of bottle neck. Defaults to 4.\n",
    "            kernel_size (int, optional): The kernel for the middle convolution. Defaults to 3.\n",
    "            stride (int, optional): The stride for the middle convolution and the shortcut. Defaults to 1.\n",
    "            padding (str, optional): The padding for the middle convolution. Defaults to 'same'.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.residual = (in_channels == out_channels and stride == 1)\n",
    "\n",
    "        modules = nn.ModuleList()\n",
    "        bottleneck_size = int(in_channels*bottleneck)\n",
    "\n",
    "        # 1. (..., in_channels, ...) -> (..., bottleneck_size, ...)\n",
    "        if in_channels != bottleneck_size:\n",
    "            modules.append(\n",
    "                conv_block(\n",
    "                    in_channels, bottleneck_size,\n",
    "                    kernel_size=1, stride=1, padding='same',\n",
    "                    activation_layer=activation_layer,\n",
    "                    **kwargs\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # 2. (..., bottleneck_size, ...) -> (..., bottleneck_size, ...)\n",
    "        modules.append(\n",
    "            conv_block(\n",
    "                bottleneck_size, bottleneck_size,\n",
    "                kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                groups=bottleneck_size, # Depthwise Convolution\n",
    "                activation_layer=activation_layer,\n",
    "                **kwargs\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # 3. Squeeze and excitation block\n",
    "        squeeze_channels = max(1, in_channels // squeeze_ratio)\n",
    "        modules.append(\n",
    "            se_block(\n",
    "                bottleneck_size, squeeze_channels,\n",
    "                activation_layer=activation_layer,\n",
    "                conv_block=conv_block,\n",
    "                pool_block=pool_block,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # 4. (..., bottleneck_size, ...) -> (..., out_channels, ...)\n",
    "        modules.append(\n",
    "            conv_block(\n",
    "                bottleneck_size, out_channels,\n",
    "                kernel_size=1, stride=1, padding='same',\n",
    "                activation_layer=nn.Identity,\n",
    "                **kwargs\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.block = nn.Sequential(*modules)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        inp = x\n",
    "        x = self.block(x)\n",
    "\n",
    "        if self.residual:\n",
    "            x = x + inp\n",
    "\n",
    "        return x\n",
    "\n",
    "# in_channels, out_channels = 32, 4\n",
    "# kernel_size = 3\n",
    "# batch_size = 1\n",
    "# l = MBConv(\n",
    "#     in_channels, out_channels,\n",
    "#     kernel_size=kernel_size, bottleneck=1,\n",
    "#     squeeze_ratio=in_channels//6\n",
    "# )\n",
    "# x = torch.randn(batch_size, in_channels, 20, 20)\n",
    "# out = l(x)\n",
    "# x.shape, out.shape\n",
    "\n",
    "# print(summary(\n",
    "#     model=l, \n",
    "#     input_data=x,\n",
    "#     col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#     col_width=20,\n",
    "#     row_settings=[\"var_names\"]\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model\n",
    "\n",
    "* ReLU6 and SiLU usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. EfficientNetConfig\n",
    "\n",
    "#### TODO\n",
    "- [x] Pipe activation_layer all the way through.\n",
    "- [x] Residual connection in SEBlock is broken for stride != 1.\n",
    "- [x] Round channels to multiple of 8.\n",
    "- [-] Pipe dropout.\n",
    "- [-] Configure the minimum number of channels in EfficientNetConfig.\n",
    "- [x] Adjust variable blocks to have same number of input and output channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================================================================================\n",
      "Layer (type (var_name))                                 Input Shape          Output Shape         Param #              Trainable\n",
      "=======================================================================================================================================\n",
      "Sequential (Sequential)                                 [1, 48, 224, 224]    [1, 448, 14, 14]     --                   True\n",
      "├─Sequential (0)                                        [1, 48, 224, 224]    [1, 24, 224, 224]    --                   True\n",
      "│    └─MBConv (0)                                       [1, 48, 224, 224]    [1, 24, 224, 224]    --                   True\n",
      "│    │    └─Sequential (block)                          [1, 48, 224, 224]    [1, 24, 224, 224]    --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 48, 224, 224]    [1, 48, 224, 224]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 48, 224, 224]    [1, 48, 224, 224]    432                  True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 48, 224, 224]    [1, 48, 224, 224]    96                   True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 48, 224, 224]    [1, 48, 224, 224]    --                   --\n",
      "│    │    │    └─SEBlock (1)                            [1, 48, 224, 224]    [1, 48, 224, 224]    --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 48, 224, 224]    [1, 48, 1, 1]        --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 48, 1, 1]        [1, 12, 1, 1]        588                  True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 12, 1, 1]        [1, 48, 1, 1]        624                  True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 48, 1, 1]        [1, 48, 1, 1]        --                   --\n",
      "│    │    │    └─Conv2dNormActivation (2)               [1, 48, 224, 224]    [1, 24, 224, 224]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 48, 224, 224]    [1, 24, 224, 224]    1,152                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 24, 224, 224]    [1, 24, 224, 224]    48                   True\n",
      "│    │    │    │    └─Identity (2)                      [1, 24, 224, 224]    [1, 24, 224, 224]    --                   --\n",
      "│    └─MBConv (1)                                       [1, 24, 224, 224]    [1, 24, 224, 224]    --                   True\n",
      "│    │    └─Sequential (block)                          [1, 24, 224, 224]    [1, 24, 224, 224]    --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 24, 224, 224]    [1, 24, 224, 224]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 24, 224, 224]    [1, 24, 224, 224]    216                  True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 24, 224, 224]    [1, 24, 224, 224]    48                   True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 24, 224, 224]    [1, 24, 224, 224]    --                   --\n",
      "│    │    │    └─SEBlock (1)                            [1, 24, 224, 224]    [1, 24, 224, 224]    --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 24, 224, 224]    [1, 24, 1, 1]        --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 24, 1, 1]        [1, 6, 1, 1]         150                  True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 6, 1, 1]         [1, 24, 1, 1]        168                  True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 24, 1, 1]        [1, 24, 1, 1]        --                   --\n",
      "│    │    │    └─Conv2dNormActivation (2)               [1, 24, 224, 224]    [1, 24, 224, 224]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 24, 224, 224]    [1, 24, 224, 224]    576                  True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 24, 224, 224]    [1, 24, 224, 224]    48                   True\n",
      "│    │    │    │    └─Identity (2)                      [1, 24, 224, 224]    [1, 24, 224, 224]    --                   --\n",
      "├─Sequential (1)                                        [1, 24, 224, 224]    [1, 32, 112, 112]    --                   True\n",
      "│    └─MBConv (0)                                       [1, 24, 224, 224]    [1, 32, 112, 112]    --                   True\n",
      "│    │    └─Sequential (block)                          [1, 24, 224, 224]    [1, 32, 112, 112]    --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 24, 224, 224]    [1, 144, 224, 224]   --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 24, 224, 224]    [1, 144, 224, 224]   3,456                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 144, 224, 224]   [1, 144, 224, 224]   288                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 144, 224, 224]   [1, 144, 224, 224]   --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 144, 224, 224]   [1, 144, 112, 112]   --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 144, 224, 224]   [1, 144, 112, 112]   1,296                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 144, 112, 112]   [1, 144, 112, 112]   288                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 144, 112, 112]   [1, 144, 112, 112]   --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 144, 112, 112]   [1, 144, 112, 112]   --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 144, 112, 112]   [1, 144, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 144, 1, 1]       [1, 6, 1, 1]         870                  True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 6, 1, 1]         [1, 144, 1, 1]       1,008                True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 144, 1, 1]       [1, 144, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 144, 112, 112]   [1, 32, 112, 112]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 144, 112, 112]   [1, 32, 112, 112]    4,608                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 32, 112, 112]    [1, 32, 112, 112]    64                   True\n",
      "│    │    │    │    └─Identity (2)                      [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n",
      "│    └─MBConv (1)                                       [1, 32, 112, 112]    [1, 32, 112, 112]    --                   True\n",
      "│    │    └─Sequential (block)                          [1, 32, 112, 112]    [1, 32, 112, 112]    --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 32, 112, 112]    [1, 192, 112, 112]   --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 32, 112, 112]    [1, 192, 112, 112]   6,144                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 192, 112, 112]   [1, 192, 112, 112]   384                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 192, 112, 112]   [1, 192, 112, 112]   --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 192, 112, 112]   [1, 192, 112, 112]   --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 192, 112, 112]   [1, 192, 112, 112]   1,728                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 192, 112, 112]   [1, 192, 112, 112]   384                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 192, 112, 112]   [1, 192, 112, 112]   --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 192, 112, 112]   [1, 192, 112, 112]   --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 192, 112, 112]   [1, 192, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 192, 1, 1]       [1, 8, 1, 1]         1,544                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 8, 1, 1]         [1, 192, 1, 1]       1,728                True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 192, 1, 1]       [1, 192, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 192, 112, 112]   [1, 32, 112, 112]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 192, 112, 112]   [1, 32, 112, 112]    6,144                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 32, 112, 112]    [1, 32, 112, 112]    64                   True\n",
      "│    │    │    │    └─Identity (2)                      [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n",
      "│    └─MBConv (2)                                       [1, 32, 112, 112]    [1, 32, 112, 112]    --                   True\n",
      "│    │    └─Sequential (block)                          [1, 32, 112, 112]    [1, 32, 112, 112]    --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 32, 112, 112]    [1, 192, 112, 112]   --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 32, 112, 112]    [1, 192, 112, 112]   6,144                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 192, 112, 112]   [1, 192, 112, 112]   384                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 192, 112, 112]   [1, 192, 112, 112]   --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 192, 112, 112]   [1, 192, 112, 112]   --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 192, 112, 112]   [1, 192, 112, 112]   1,728                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 192, 112, 112]   [1, 192, 112, 112]   384                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 192, 112, 112]   [1, 192, 112, 112]   --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 192, 112, 112]   [1, 192, 112, 112]   --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 192, 112, 112]   [1, 192, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 192, 1, 1]       [1, 8, 1, 1]         1,544                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 8, 1, 1]         [1, 192, 1, 1]       1,728                True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 192, 1, 1]       [1, 192, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 192, 112, 112]   [1, 32, 112, 112]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 192, 112, 112]   [1, 32, 112, 112]    6,144                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 32, 112, 112]    [1, 32, 112, 112]    64                   True\n",
      "│    │    │    │    └─Identity (2)                      [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n",
      "│    └─MBConv (3)                                       [1, 32, 112, 112]    [1, 32, 112, 112]    --                   True\n",
      "│    │    └─Sequential (block)                          [1, 32, 112, 112]    [1, 32, 112, 112]    --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 32, 112, 112]    [1, 192, 112, 112]   --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 32, 112, 112]    [1, 192, 112, 112]   6,144                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 192, 112, 112]   [1, 192, 112, 112]   384                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 192, 112, 112]   [1, 192, 112, 112]   --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 192, 112, 112]   [1, 192, 112, 112]   --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 192, 112, 112]   [1, 192, 112, 112]   1,728                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 192, 112, 112]   [1, 192, 112, 112]   384                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 192, 112, 112]   [1, 192, 112, 112]   --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 192, 112, 112]   [1, 192, 112, 112]   --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 192, 112, 112]   [1, 192, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 192, 1, 1]       [1, 8, 1, 1]         1,544                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 8, 1, 1]         [1, 192, 1, 1]       1,728                True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 192, 1, 1]       [1, 192, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 192, 112, 112]   [1, 32, 112, 112]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 192, 112, 112]   [1, 32, 112, 112]    6,144                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 32, 112, 112]    [1, 32, 112, 112]    64                   True\n",
      "│    │    │    │    └─Identity (2)                      [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n",
      "├─Sequential (2)                                        [1, 32, 112, 112]    [1, 56, 56, 56]      --                   True\n",
      "│    └─MBConv (0)                                       [1, 32, 112, 112]    [1, 56, 56, 56]      --                   True\n",
      "│    │    └─Sequential (block)                          [1, 32, 112, 112]    [1, 56, 56, 56]      --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 32, 112, 112]    [1, 192, 112, 112]   --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 32, 112, 112]    [1, 192, 112, 112]   6,144                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 192, 112, 112]   [1, 192, 112, 112]   384                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 192, 112, 112]   [1, 192, 112, 112]   --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 192, 112, 112]   [1, 192, 56, 56]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 192, 112, 112]   [1, 192, 56, 56]     4,800                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 192, 56, 56]     [1, 192, 56, 56]     384                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 192, 56, 56]     [1, 192, 56, 56]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 192, 56, 56]     [1, 192, 56, 56]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 192, 56, 56]     [1, 192, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 192, 1, 1]       [1, 8, 1, 1]         1,544                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 8, 1, 1]         [1, 192, 1, 1]       1,728                True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 192, 1, 1]       [1, 192, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 192, 56, 56]     [1, 56, 56, 56]      --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 192, 56, 56]     [1, 56, 56, 56]      10,752               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 56, 56, 56]      [1, 56, 56, 56]      112                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 56, 56, 56]      [1, 56, 56, 56]      --                   --\n",
      "│    └─MBConv (1)                                       [1, 56, 56, 56]      [1, 56, 56, 56]      --                   True\n",
      "│    │    └─Sequential (block)                          [1, 56, 56, 56]      [1, 56, 56, 56]      --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 56, 56, 56]      [1, 336, 56, 56]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 56, 56, 56]      [1, 336, 56, 56]     18,816               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 336, 56, 56]     [1, 336, 56, 56]     672                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 336, 56, 56]     [1, 336, 56, 56]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 336, 56, 56]     [1, 336, 56, 56]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 336, 56, 56]     [1, 336, 56, 56]     8,400                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 336, 56, 56]     [1, 336, 56, 56]     672                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 336, 56, 56]     [1, 336, 56, 56]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 336, 56, 56]     [1, 336, 56, 56]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 336, 56, 56]     [1, 336, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 336, 1, 1]       [1, 14, 1, 1]        4,718                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 14, 1, 1]        [1, 336, 1, 1]       5,040                True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 336, 1, 1]       [1, 336, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 336, 56, 56]     [1, 56, 56, 56]      --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 336, 56, 56]     [1, 56, 56, 56]      18,816               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 56, 56, 56]      [1, 56, 56, 56]      112                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 56, 56, 56]      [1, 56, 56, 56]      --                   --\n",
      "│    └─MBConv (2)                                       [1, 56, 56, 56]      [1, 56, 56, 56]      --                   True\n",
      "│    │    └─Sequential (block)                          [1, 56, 56, 56]      [1, 56, 56, 56]      --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 56, 56, 56]      [1, 336, 56, 56]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 56, 56, 56]      [1, 336, 56, 56]     18,816               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 336, 56, 56]     [1, 336, 56, 56]     672                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 336, 56, 56]     [1, 336, 56, 56]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 336, 56, 56]     [1, 336, 56, 56]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 336, 56, 56]     [1, 336, 56, 56]     8,400                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 336, 56, 56]     [1, 336, 56, 56]     672                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 336, 56, 56]     [1, 336, 56, 56]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 336, 56, 56]     [1, 336, 56, 56]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 336, 56, 56]     [1, 336, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 336, 1, 1]       [1, 14, 1, 1]        4,718                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 14, 1, 1]        [1, 336, 1, 1]       5,040                True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 336, 1, 1]       [1, 336, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 336, 56, 56]     [1, 56, 56, 56]      --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 336, 56, 56]     [1, 56, 56, 56]      18,816               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 56, 56, 56]      [1, 56, 56, 56]      112                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 56, 56, 56]      [1, 56, 56, 56]      --                   --\n",
      "│    └─MBConv (3)                                       [1, 56, 56, 56]      [1, 56, 56, 56]      --                   True\n",
      "│    │    └─Sequential (block)                          [1, 56, 56, 56]      [1, 56, 56, 56]      --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 56, 56, 56]      [1, 336, 56, 56]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 56, 56, 56]      [1, 336, 56, 56]     18,816               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 336, 56, 56]     [1, 336, 56, 56]     672                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 336, 56, 56]     [1, 336, 56, 56]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 336, 56, 56]     [1, 336, 56, 56]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 336, 56, 56]     [1, 336, 56, 56]     8,400                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 336, 56, 56]     [1, 336, 56, 56]     672                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 336, 56, 56]     [1, 336, 56, 56]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 336, 56, 56]     [1, 336, 56, 56]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 336, 56, 56]     [1, 336, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 336, 1, 1]       [1, 14, 1, 1]        4,718                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 14, 1, 1]        [1, 336, 1, 1]       5,040                True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 336, 1, 1]       [1, 336, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 336, 56, 56]     [1, 56, 56, 56]      --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 336, 56, 56]     [1, 56, 56, 56]      18,816               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 56, 56, 56]      [1, 56, 56, 56]      112                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 56, 56, 56]      [1, 56, 56, 56]      --                   --\n",
      "├─Sequential (3)                                        [1, 56, 56, 56]      [1, 112, 28, 28]     --                   True\n",
      "│    └─MBConv (0)                                       [1, 56, 56, 56]      [1, 112, 28, 28]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 56, 56, 56]      [1, 112, 28, 28]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 56, 56, 56]      [1, 336, 56, 56]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 56, 56, 56]      [1, 336, 56, 56]     18,816               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 336, 56, 56]     [1, 336, 56, 56]     672                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 336, 56, 56]     [1, 336, 56, 56]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 336, 56, 56]     [1, 336, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 336, 56, 56]     [1, 336, 28, 28]     3,024                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 336, 28, 28]     [1, 336, 28, 28]     672                  True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 336, 28, 28]     [1, 336, 28, 28]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 336, 28, 28]     [1, 336, 28, 28]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 336, 28, 28]     [1, 336, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 336, 1, 1]       [1, 14, 1, 1]        4,718                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 14, 1, 1]        [1, 336, 1, 1]       5,040                True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 336, 1, 1]       [1, 336, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 336, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 336, 28, 28]     [1, 112, 28, 28]     37,632               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 112, 28, 28]     [1, 112, 28, 28]     224                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 112, 28, 28]     [1, 112, 28, 28]     --                   --\n",
      "│    └─MBConv (1)                                       [1, 112, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 112, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 112, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 112, 28, 28]     [1, 672, 28, 28]     75,264               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 672, 28, 28]     [1, 672, 28, 28]     1,344                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 672, 28, 28]     [1, 672, 28, 28]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 672, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 672, 28, 28]     [1, 672, 28, 28]     6,048                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 672, 28, 28]     [1, 672, 28, 28]     1,344                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 672, 28, 28]     [1, 672, 28, 28]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 672, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 672, 28, 28]     [1, 672, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 672, 1, 1]       [1, 28, 1, 1]        18,844               True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 28, 1, 1]        [1, 672, 1, 1]       19,488               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 672, 1, 1]       [1, 672, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 672, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 672, 28, 28]     [1, 112, 28, 28]     75,264               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 112, 28, 28]     [1, 112, 28, 28]     224                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 112, 28, 28]     [1, 112, 28, 28]     --                   --\n",
      "│    └─MBConv (2)                                       [1, 112, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 112, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 112, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 112, 28, 28]     [1, 672, 28, 28]     75,264               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 672, 28, 28]     [1, 672, 28, 28]     1,344                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 672, 28, 28]     [1, 672, 28, 28]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 672, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 672, 28, 28]     [1, 672, 28, 28]     6,048                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 672, 28, 28]     [1, 672, 28, 28]     1,344                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 672, 28, 28]     [1, 672, 28, 28]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 672, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 672, 28, 28]     [1, 672, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 672, 1, 1]       [1, 28, 1, 1]        18,844               True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 28, 1, 1]        [1, 672, 1, 1]       19,488               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 672, 1, 1]       [1, 672, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 672, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 672, 28, 28]     [1, 112, 28, 28]     75,264               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 112, 28, 28]     [1, 112, 28, 28]     224                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 112, 28, 28]     [1, 112, 28, 28]     --                   --\n",
      "│    └─MBConv (3)                                       [1, 112, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 112, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 112, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 112, 28, 28]     [1, 672, 28, 28]     75,264               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 672, 28, 28]     [1, 672, 28, 28]     1,344                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 672, 28, 28]     [1, 672, 28, 28]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 672, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 672, 28, 28]     [1, 672, 28, 28]     6,048                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 672, 28, 28]     [1, 672, 28, 28]     1,344                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 672, 28, 28]     [1, 672, 28, 28]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 672, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 672, 28, 28]     [1, 672, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 672, 1, 1]       [1, 28, 1, 1]        18,844               True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 28, 1, 1]        [1, 672, 1, 1]       19,488               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 672, 1, 1]       [1, 672, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 672, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 672, 28, 28]     [1, 112, 28, 28]     75,264               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 112, 28, 28]     [1, 112, 28, 28]     224                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 112, 28, 28]     [1, 112, 28, 28]     --                   --\n",
      "│    └─MBConv (4)                                       [1, 112, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 112, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 112, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 112, 28, 28]     [1, 672, 28, 28]     75,264               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 672, 28, 28]     [1, 672, 28, 28]     1,344                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 672, 28, 28]     [1, 672, 28, 28]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 672, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 672, 28, 28]     [1, 672, 28, 28]     6,048                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 672, 28, 28]     [1, 672, 28, 28]     1,344                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 672, 28, 28]     [1, 672, 28, 28]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 672, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 672, 28, 28]     [1, 672, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 672, 1, 1]       [1, 28, 1, 1]        18,844               True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 28, 1, 1]        [1, 672, 1, 1]       19,488               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 672, 1, 1]       [1, 672, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 672, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 672, 28, 28]     [1, 112, 28, 28]     75,264               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 112, 28, 28]     [1, 112, 28, 28]     224                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 112, 28, 28]     [1, 112, 28, 28]     --                   --\n",
      "│    └─MBConv (5)                                       [1, 112, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 112, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 112, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 112, 28, 28]     [1, 672, 28, 28]     75,264               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 672, 28, 28]     [1, 672, 28, 28]     1,344                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 672, 28, 28]     [1, 672, 28, 28]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 672, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 672, 28, 28]     [1, 672, 28, 28]     6,048                True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 672, 28, 28]     [1, 672, 28, 28]     1,344                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 672, 28, 28]     [1, 672, 28, 28]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 672, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 672, 28, 28]     [1, 672, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 672, 1, 1]       [1, 28, 1, 1]        18,844               True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 28, 1, 1]        [1, 672, 1, 1]       19,488               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 672, 1, 1]       [1, 672, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 672, 28, 28]     [1, 112, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 672, 28, 28]     [1, 112, 28, 28]     75,264               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 112, 28, 28]     [1, 112, 28, 28]     224                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 112, 28, 28]     [1, 112, 28, 28]     --                   --\n",
      "├─Sequential (4)                                        [1, 112, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    └─MBConv (0)                                       [1, 112, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 112, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 112, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 112, 28, 28]     [1, 672, 28, 28]     75,264               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 672, 28, 28]     [1, 672, 28, 28]     1,344                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 672, 28, 28]     [1, 672, 28, 28]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 672, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 672, 28, 28]     [1, 672, 28, 28]     16,800               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 672, 28, 28]     [1, 672, 28, 28]     1,344                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 672, 28, 28]     [1, 672, 28, 28]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 672, 28, 28]     [1, 672, 28, 28]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 672, 28, 28]     [1, 672, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 672, 1, 1]       [1, 28, 1, 1]        18,844               True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 28, 1, 1]        [1, 672, 1, 1]       19,488               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 672, 1, 1]       [1, 672, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 672, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 672, 28, 28]     [1, 160, 28, 28]     107,520              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 160, 28, 28]     [1, 160, 28, 28]     320                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 160, 28, 28]     [1, 160, 28, 28]     --                   --\n",
      "│    └─MBConv (1)                                       [1, 160, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 160, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 160, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 160, 28, 28]     [1, 960, 28, 28]     153,600              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 960, 28, 28]     [1, 960, 28, 28]     1,920                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 960, 28, 28]     [1, 960, 28, 28]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 960, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 960, 28, 28]     [1, 960, 28, 28]     24,000               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 960, 28, 28]     [1, 960, 28, 28]     1,920                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 960, 28, 28]     [1, 960, 28, 28]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 960, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 960, 28, 28]     [1, 960, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 960, 1, 1]       [1, 40, 1, 1]        38,440               True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 40, 1, 1]        [1, 960, 1, 1]       39,360               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 960, 1, 1]       [1, 960, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 960, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 960, 28, 28]     [1, 160, 28, 28]     153,600              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 160, 28, 28]     [1, 160, 28, 28]     320                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 160, 28, 28]     [1, 160, 28, 28]     --                   --\n",
      "│    └─MBConv (2)                                       [1, 160, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 160, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 160, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 160, 28, 28]     [1, 960, 28, 28]     153,600              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 960, 28, 28]     [1, 960, 28, 28]     1,920                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 960, 28, 28]     [1, 960, 28, 28]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 960, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 960, 28, 28]     [1, 960, 28, 28]     24,000               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 960, 28, 28]     [1, 960, 28, 28]     1,920                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 960, 28, 28]     [1, 960, 28, 28]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 960, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 960, 28, 28]     [1, 960, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 960, 1, 1]       [1, 40, 1, 1]        38,440               True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 40, 1, 1]        [1, 960, 1, 1]       39,360               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 960, 1, 1]       [1, 960, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 960, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 960, 28, 28]     [1, 160, 28, 28]     153,600              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 160, 28, 28]     [1, 160, 28, 28]     320                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 160, 28, 28]     [1, 160, 28, 28]     --                   --\n",
      "│    └─MBConv (3)                                       [1, 160, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 160, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 160, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 160, 28, 28]     [1, 960, 28, 28]     153,600              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 960, 28, 28]     [1, 960, 28, 28]     1,920                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 960, 28, 28]     [1, 960, 28, 28]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 960, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 960, 28, 28]     [1, 960, 28, 28]     24,000               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 960, 28, 28]     [1, 960, 28, 28]     1,920                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 960, 28, 28]     [1, 960, 28, 28]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 960, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 960, 28, 28]     [1, 960, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 960, 1, 1]       [1, 40, 1, 1]        38,440               True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 40, 1, 1]        [1, 960, 1, 1]       39,360               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 960, 1, 1]       [1, 960, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 960, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 960, 28, 28]     [1, 160, 28, 28]     153,600              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 160, 28, 28]     [1, 160, 28, 28]     320                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 160, 28, 28]     [1, 160, 28, 28]     --                   --\n",
      "│    └─MBConv (4)                                       [1, 160, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 160, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 160, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 160, 28, 28]     [1, 960, 28, 28]     153,600              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 960, 28, 28]     [1, 960, 28, 28]     1,920                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 960, 28, 28]     [1, 960, 28, 28]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 960, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 960, 28, 28]     [1, 960, 28, 28]     24,000               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 960, 28, 28]     [1, 960, 28, 28]     1,920                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 960, 28, 28]     [1, 960, 28, 28]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 960, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 960, 28, 28]     [1, 960, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 960, 1, 1]       [1, 40, 1, 1]        38,440               True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 40, 1, 1]        [1, 960, 1, 1]       39,360               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 960, 1, 1]       [1, 960, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 960, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 960, 28, 28]     [1, 160, 28, 28]     153,600              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 160, 28, 28]     [1, 160, 28, 28]     320                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 160, 28, 28]     [1, 160, 28, 28]     --                   --\n",
      "│    └─MBConv (5)                                       [1, 160, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 160, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 160, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 160, 28, 28]     [1, 960, 28, 28]     153,600              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 960, 28, 28]     [1, 960, 28, 28]     1,920                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 960, 28, 28]     [1, 960, 28, 28]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 960, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 960, 28, 28]     [1, 960, 28, 28]     24,000               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 960, 28, 28]     [1, 960, 28, 28]     1,920                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 960, 28, 28]     [1, 960, 28, 28]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 960, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 960, 28, 28]     [1, 960, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 960, 1, 1]       [1, 40, 1, 1]        38,440               True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 40, 1, 1]        [1, 960, 1, 1]       39,360               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 960, 1, 1]       [1, 960, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 960, 28, 28]     [1, 160, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 960, 28, 28]     [1, 160, 28, 28]     153,600              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 160, 28, 28]     [1, 160, 28, 28]     320                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 160, 28, 28]     [1, 160, 28, 28]     --                   --\n",
      "├─Sequential (5)                                        [1, 160, 28, 28]     [1, 272, 14, 14]     --                   True\n",
      "│    └─MBConv (0)                                       [1, 160, 28, 28]     [1, 272, 14, 14]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 160, 28, 28]     [1, 272, 14, 14]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 160, 28, 28]     [1, 960, 28, 28]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 160, 28, 28]     [1, 960, 28, 28]     153,600              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 960, 28, 28]     [1, 960, 28, 28]     1,920                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 960, 28, 28]     [1, 960, 28, 28]     --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 960, 28, 28]     [1, 960, 14, 14]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 960, 28, 28]     [1, 960, 14, 14]     24,000               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 960, 14, 14]     [1, 960, 14, 14]     1,920                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 960, 14, 14]     [1, 960, 14, 14]     --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 960, 14, 14]     [1, 960, 14, 14]     --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 960, 14, 14]     [1, 960, 1, 1]       --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 960, 1, 1]       [1, 6, 1, 1]         5,766                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 6, 1, 1]         [1, 960, 1, 1]       6,720                True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 960, 1, 1]       [1, 960, 1, 1]       --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 960, 14, 14]     [1, 272, 14, 14]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 960, 14, 14]     [1, 272, 14, 14]     261,120              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 272, 14, 14]     [1, 272, 14, 14]     544                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 272, 14, 14]     [1, 272, 14, 14]     --                   --\n",
      "│    └─MBConv (1)                                       [1, 272, 14, 14]     [1, 272, 14, 14]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 272, 14, 14]     [1, 272, 14, 14]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 272, 14, 14]     [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 272, 14, 14]     [1, 1632, 14, 14]    443,904              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 1632, 14, 14]    40,800               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 1632, 14, 14]    [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 1632, 1, 1]      [1, 6, 1, 1]         9,798                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 6, 1, 1]         [1, 1632, 1, 1]      11,424               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 1632, 1, 1]      [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 1632, 14, 14]    [1, 272, 14, 14]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 272, 14, 14]     443,904              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 272, 14, 14]     [1, 272, 14, 14]     544                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 272, 14, 14]     [1, 272, 14, 14]     --                   --\n",
      "│    └─MBConv (2)                                       [1, 272, 14, 14]     [1, 272, 14, 14]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 272, 14, 14]     [1, 272, 14, 14]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 272, 14, 14]     [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 272, 14, 14]     [1, 1632, 14, 14]    443,904              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 1632, 14, 14]    40,800               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 1632, 14, 14]    [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 1632, 1, 1]      [1, 6, 1, 1]         9,798                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 6, 1, 1]         [1, 1632, 1, 1]      11,424               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 1632, 1, 1]      [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 1632, 14, 14]    [1, 272, 14, 14]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 272, 14, 14]     443,904              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 272, 14, 14]     [1, 272, 14, 14]     544                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 272, 14, 14]     [1, 272, 14, 14]     --                   --\n",
      "│    └─MBConv (3)                                       [1, 272, 14, 14]     [1, 272, 14, 14]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 272, 14, 14]     [1, 272, 14, 14]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 272, 14, 14]     [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 272, 14, 14]     [1, 1632, 14, 14]    443,904              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 1632, 14, 14]    40,800               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 1632, 14, 14]    [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 1632, 1, 1]      [1, 6, 1, 1]         9,798                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 6, 1, 1]         [1, 1632, 1, 1]      11,424               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 1632, 1, 1]      [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 1632, 14, 14]    [1, 272, 14, 14]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 272, 14, 14]     443,904              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 272, 14, 14]     [1, 272, 14, 14]     544                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 272, 14, 14]     [1, 272, 14, 14]     --                   --\n",
      "│    └─MBConv (4)                                       [1, 272, 14, 14]     [1, 272, 14, 14]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 272, 14, 14]     [1, 272, 14, 14]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 272, 14, 14]     [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 272, 14, 14]     [1, 1632, 14, 14]    443,904              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 1632, 14, 14]    40,800               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 1632, 14, 14]    [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 1632, 1, 1]      [1, 6, 1, 1]         9,798                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 6, 1, 1]         [1, 1632, 1, 1]      11,424               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 1632, 1, 1]      [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 1632, 14, 14]    [1, 272, 14, 14]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 272, 14, 14]     443,904              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 272, 14, 14]     [1, 272, 14, 14]     544                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 272, 14, 14]     [1, 272, 14, 14]     --                   --\n",
      "│    └─MBConv (5)                                       [1, 272, 14, 14]     [1, 272, 14, 14]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 272, 14, 14]     [1, 272, 14, 14]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 272, 14, 14]     [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 272, 14, 14]     [1, 1632, 14, 14]    443,904              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 1632, 14, 14]    40,800               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 1632, 14, 14]    [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 1632, 1, 1]      [1, 6, 1, 1]         9,798                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 6, 1, 1]         [1, 1632, 1, 1]      11,424               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 1632, 1, 1]      [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 1632, 14, 14]    [1, 272, 14, 14]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 272, 14, 14]     443,904              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 272, 14, 14]     [1, 272, 14, 14]     544                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 272, 14, 14]     [1, 272, 14, 14]     --                   --\n",
      "│    └─MBConv (6)                                       [1, 272, 14, 14]     [1, 272, 14, 14]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 272, 14, 14]     [1, 272, 14, 14]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 272, 14, 14]     [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 272, 14, 14]     [1, 1632, 14, 14]    443,904              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 1632, 14, 14]    40,800               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 1632, 14, 14]    [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 1632, 1, 1]      [1, 6, 1, 1]         9,798                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 6, 1, 1]         [1, 1632, 1, 1]      11,424               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 1632, 1, 1]      [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 1632, 14, 14]    [1, 272, 14, 14]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 272, 14, 14]     443,904              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 272, 14, 14]     [1, 272, 14, 14]     544                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 272, 14, 14]     [1, 272, 14, 14]     --                   --\n",
      "│    └─MBConv (7)                                       [1, 272, 14, 14]     [1, 272, 14, 14]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 272, 14, 14]     [1, 272, 14, 14]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 272, 14, 14]     [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 272, 14, 14]     [1, 1632, 14, 14]    443,904              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 1632, 14, 14]    40,800               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 1632, 14, 14]    [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 1632, 1, 1]      [1, 6, 1, 1]         9,798                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 6, 1, 1]         [1, 1632, 1, 1]      11,424               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 1632, 1, 1]      [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 1632, 14, 14]    [1, 272, 14, 14]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 272, 14, 14]     443,904              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 272, 14, 14]     [1, 272, 14, 14]     544                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 272, 14, 14]     [1, 272, 14, 14]     --                   --\n",
      "├─Sequential (6)                                        [1, 272, 14, 14]     [1, 448, 14, 14]     --                   True\n",
      "│    └─MBConv (0)                                       [1, 272, 14, 14]     [1, 448, 14, 14]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 272, 14, 14]     [1, 448, 14, 14]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 272, 14, 14]     [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 272, 14, 14]     [1, 1632, 14, 14]    443,904              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 1632, 14, 14]    14,688               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 1632, 14, 14]    [1, 1632, 14, 14]    3,264                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 1632, 14, 14]    [1, 1632, 14, 14]    --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 1632, 14, 14]    [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 1632, 1, 1]      [1, 6, 1, 1]         9,798                True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 6, 1, 1]         [1, 1632, 1, 1]      11,424               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 1632, 1, 1]      [1, 1632, 1, 1]      --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 1632, 14, 14]    [1, 448, 14, 14]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 1632, 14, 14]    [1, 448, 14, 14]     731,136              True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 448, 14, 14]     [1, 448, 14, 14]     896                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 448, 14, 14]     [1, 448, 14, 14]     --                   --\n",
      "│    └─MBConv (1)                                       [1, 448, 14, 14]     [1, 448, 14, 14]     --                   True\n",
      "│    │    └─Sequential (block)                          [1, 448, 14, 14]     [1, 448, 14, 14]     --                   True\n",
      "│    │    │    └─Conv2dNormActivation (0)               [1, 448, 14, 14]     [1, 2688, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 448, 14, 14]     [1, 2688, 14, 14]    1,204,224            True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 2688, 14, 14]    [1, 2688, 14, 14]    5,376                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 2688, 14, 14]    [1, 2688, 14, 14]    --                   --\n",
      "│    │    │    └─Conv2dNormActivation (1)               [1, 2688, 14, 14]    [1, 2688, 14, 14]    --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 2688, 14, 14]    [1, 2688, 14, 14]    24,192               True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 2688, 14, 14]    [1, 2688, 14, 14]    5,376                True\n",
      "│    │    │    │    └─SiLU (2)                          [1, 2688, 14, 14]    [1, 2688, 14, 14]    --                   --\n",
      "│    │    │    └─SEBlock (2)                            [1, 2688, 14, 14]    [1, 2688, 14, 14]    --                   True\n",
      "│    │    │    │    └─AdaptiveAvgPool2d (pool)          [1, 2688, 14, 14]    [1, 2688, 1, 1]      --                   --\n",
      "│    │    │    │    └─Conv2dNormActivation (conv1)      [1, 2688, 1, 1]      [1, 6, 1, 1]         16,134               True\n",
      "│    │    │    │    └─Conv2dNormActivation (conv2)      [1, 6, 1, 1]         [1, 2688, 1, 1]      18,816               True\n",
      "│    │    │    │    └─Sigmoid (sigmoid)                 [1, 2688, 1, 1]      [1, 2688, 1, 1]      --                   --\n",
      "│    │    │    └─Conv2dNormActivation (3)               [1, 2688, 14, 14]    [1, 448, 14, 14]     --                   True\n",
      "│    │    │    │    └─Conv2d (0)                        [1, 2688, 14, 14]    [1, 448, 14, 14]     1,204,224            True\n",
      "│    │    │    │    └─BatchNorm2d (1)                   [1, 448, 14, 14]     [1, 448, 14, 14]     896                  True\n",
      "│    │    │    │    └─Identity (2)                      [1, 448, 14, 14]     [1, 448, 14, 14]     --                   --\n",
      "=======================================================================================================================================\n",
      "Total params: 14,486,108\n",
      "Trainable params: 14,486,108\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 5.77\n",
      "=======================================================================================================================================\n",
      "Input size (MB): 9.63\n",
      "Forward/backward pass size (MB): 1045.09\n",
      "Params size (MB): 57.94\n",
      "Estimated Total Size (MB): 1112.67\n",
      "=======================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.ops as ops\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "class EfficientNetConfig(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # B4 configuration\n",
    "        width_mult=1.4, depth_mult=1.8, dropout=0.4, last_channels=1280,\n",
    "\n",
    "        # Block configuration\n",
    "        kernel_1=3, kernel_2=5,\n",
    "\n",
    "        # Blocks\n",
    "        se_block=ChannelSeBlock,\n",
    "        conv_block=ops.Conv2dNormActivation,\n",
    "        pool_block=nn.AdaptiveAvgPool2d,\n",
    "    ):\n",
    "        self.width_mult = width_mult\n",
    "        self.depth_mult =depth_mult\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.last_channels = last_channels\n",
    "\n",
    "        # Conv type 1\n",
    "        self.kernel_1 = kernel_1\n",
    "\n",
    "        # Conv type 2\n",
    "        self.kernel_2 = kernel_2\n",
    "\n",
    "        # Blocks\n",
    "        self.se_block = se_block\n",
    "        self.conv_block = conv_block\n",
    "        self.pool_block = pool_block\n",
    "\n",
    "        # MBConv configs\n",
    "        self.block_configs = [\n",
    "            # (in_channels, out_channels, bottleneck, squeeze_channels, kernel, padding, stride, layers)\n",
    "            (32, 16, 1, None, kernel_1, 'same', 1, 1),\n",
    "            (16, 24, 6, None, 3, 1, 2, 2),\n",
    "            (24, 40, 6, None, 5, 2, 2, 2),\n",
    "            (40, 80, 6, None, 3, 1, 2, 3),\n",
    "            (80, 112, 6, None, kernel_2, 'same', 1, 3),\n",
    "            (112, 192, 6, 6, 5, 2, 2, 4),\n",
    "            (192, 320, 6, 6, kernel_1, 'same', 1, 1),\n",
    "        ]\n",
    "\n",
    "    def adjust_channels(self, channels):\n",
    "        return self.round_to(channels*self.width_mult)\n",
    "    \n",
    "    def adjust_depth(self, num_layers):\n",
    "        return int(math.ceil(num_layers*self.depth_mult))\n",
    "    \n",
    "    @staticmethod\n",
    "    def round_to(v, multiple=8):\n",
    "        return int(multiple * round(v / multiple))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_squeeze_ratio(channels, squeeze_channels, default=4):\n",
    "        return channels//squeeze_channels if squeeze_channels else default\n",
    "    \n",
    "    def _block(self, args, **kwargs):\n",
    "        in_channels, out_channels, bottleneck, squeeze_channels, kernel, padding, stride, layers = args\n",
    "\n",
    "        # 1. Update in_channels and out_channels based on the width_mult\n",
    "        in_channels = self.adjust_channels(in_channels)\n",
    "        out_channels = self.adjust_channels(out_channels)\n",
    "\n",
    "        # 2. Update layers based on depth_mult\n",
    "        layers = self.adjust_depth(layers)\n",
    "        \n",
    "        block = nn.Sequential(\n",
    "            MBConv(\n",
    "                in_channels, out_channels,\n",
    "                bottleneck=bottleneck, squeeze_ratio=self.get_squeeze_ratio(in_channels, squeeze_channels),\n",
    "                kernel_size=kernel, stride=stride, padding=padding,\n",
    "                se_block=self.se_block,\n",
    "                conv_block=self.conv_block,\n",
    "                pool_block=self.pool_block,\n",
    "                **kwargs\n",
    "            ),\n",
    "            *map(\n",
    "                lambda _: MBConv(\n",
    "                    out_channels, out_channels,\n",
    "                    bottleneck=bottleneck, squeeze_ratio=self.get_squeeze_ratio(out_channels, squeeze_channels),\n",
    "                    kernel_size=kernel, stride=1, padding='same',\n",
    "                    se_block=self.se_block,\n",
    "                    conv_block=self.conv_block,\n",
    "                    pool_block=self.pool_block,\n",
    "                    **kwargs\n",
    "                ),\n",
    "                range(layers - 1)\n",
    "            )\n",
    "        )\n",
    "        return block\n",
    "    \n",
    "    def make_blocks(self, **kwargs):\n",
    "        modules = nn.Sequential(\n",
    "            *map(\n",
    "                lambda b_config: self._block(b_config,  **kwargs),\n",
    "                self.block_configs\n",
    "            )\n",
    "        )\n",
    "        return modules\n",
    "\n",
    "eff_config = EfficientNetConfig(\n",
    "    # se_block=SEBlock,\n",
    "    # conv_block=Conv1dNormActivation,\n",
    "    # pool_block=nn.AdaptiveAvgPool1d\n",
    "    \n",
    ")\n",
    "block_config = eff_config.block_configs[0]\n",
    "block = eff_config.make_blocks()\n",
    "\n",
    "x = torch.randn(1, 48, 224, 224)\n",
    "# x = torch.randn(1, 48, 224)\n",
    "print(summary(\n",
    "    model=block, \n",
    "    input_data=x,\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"],\n",
    "    depth=5,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.ops as ops\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "class EfficientNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels, out_channels, config,\n",
    "        activation_layer=nn.SiLU,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"EfficientNet\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): The number of input channels.\n",
    "            out_channels (int): The number of output channels.\n",
    "            bottle_factor (int, optional): The size of bottle neck. Defaults to 4.\n",
    "            kernel_size (int, optional): The kernel for the middle convolution. Defaults to 3.\n",
    "            stride (int, optional): The stride for the middle convolution and the shortcut. Defaults to 1.\n",
    "            padding (str, optional): The padding for the middle convolution. Defaults to 'same'.\n",
    "            phi (float, optional): The compound scaling coefficient. Defaults to 1.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        in_mb_channels = config.adjust_channels(32)\n",
    "        out_mb_channels = config.adjust_channels(320)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            config.conv_block(\n",
    "                in_channels, in_mb_channels,\n",
    "                kernel_size=3, padding=1, stride=2,\n",
    "                activation_layer=activation_layer,\n",
    "                **kwargs,\n",
    "            ),\n",
    "            self.config.make_blocks(activation_layer=activation_layer, **kwargs),\n",
    "            config.conv_block(\n",
    "                out_mb_channels, config.last_channels,\n",
    "                kernel_size=1, activation_layer=activation_layer,\n",
    "                **kwargs,\n",
    "            ),\n",
    "            config.pool_block(1),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            # nn.Dropout(p=config.dropout, inplace=True),\n",
    "            nn.Linear(config.last_channels, out_channels),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# # in_channels, out_channels = 4, 6\n",
    "# in_channels, out_channels = 3, 6\n",
    "# eff_config = EfficientNetConfig()\n",
    "# model = EfficientNet(\n",
    "#     in_channels,\n",
    "#     out_channels,\n",
    "#     eff_config,\n",
    "# )\n",
    "\n",
    "# x = torch.randn(1, in_channels, 128, 128)\n",
    "# print(summary(\n",
    "#     model=model, \n",
    "#     input_data=x,\n",
    "#     col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#     col_width=20,\n",
    "#     row_settings=[\"var_names\"],\n",
    "#     depth=6\n",
    "# ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
