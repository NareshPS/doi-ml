{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "N_CLASSES = 102\n",
    "\n",
    "def split_label(ways=2):\n",
    "    def split_fn(x, y):\n",
    "        zero_mask = tf.zeros(tf.shape(y), dtype=y.dtype)\n",
    "\n",
    "        def label_fn(slot):\n",
    "            slot_size = tf.constant(N_CLASSES//ways, dtype=y.dtype)\n",
    "            start, end = slot*slot_size, (slot+1)*slot_size\n",
    "            start_cond = tf.math.greater_equal(y, start)\n",
    "            end_cond = tf.math.less(y, end)\n",
    "            slot_y = tf.where(tf.logical_and(start_cond, end_cond), y-start+1, zero_mask)\n",
    "\n",
    "            return slot_y\n",
    "        \n",
    "        y = tf.map_fn(label_fn, tf.range(ways, dtype=y.dtype), dtype=y.dtype)\n",
    "        y = tf.unstack(y, axis=0)\n",
    "        \n",
    "        return (x, tuple(y))\n",
    "    \n",
    "    return split_fn\n",
    "\n",
    "tds = train_ds.batch(BATCH_SIZE).map(split_label(3))\n",
    "itr = iter(tds)\n",
    "next(itr)[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images and Bounding Boxes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding boxes are transformed to HW grid. HW locations are based on YX_MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "# MAX_BOXES = 2\n",
    "# MAX_BOXES = 5\n",
    "# MAX_INPUT_BOXES = 2\n",
    "MAX_BOXES = 10\n",
    "MAX_INPUT_BOXES = 6\n",
    "\n",
    "@tf.function\n",
    "def preprocess_as_grid(item):\n",
    "    image, boxes = item['image'], item['faces']['bbox']\n",
    "\n",
    "    # Resize image to IMG_SIZE\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    box_grid = yxyx_to_hw_grid(boxes, IMG_SIZE)\n",
    "\n",
    "    return image, box_grid\n",
    "\n",
    "@tf.function\n",
    "def filter_empty_bboxes(item):\n",
    "    _, bboxes = item['image'], item['faces']['bbox']\n",
    "\n",
    "    return tf.shape(bboxes)[0] != 0\n",
    "\n",
    "# train_prep_ds = train_ds.filter(filter_empty_bboxes).map(preprocess_as_grid, num_parallel_calls=None)\n",
    "# # train_prep_ds = train_ds.filter(filter_empty_bboxes).map(preprocess_as_grid, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# val_prep_ds = val_ds.filter(filter_empty_bboxes).map(preprocess_as_grid, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# test_prep_ds = test_ds.map(preprocess_as_grid, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# # bitr = iter(train_prep_ds.batch(2))\n",
    "# # images, bboxes = next(bitr)\n",
    "# # images.shape, bboxes.shape\n",
    "\n",
    "# itr = iter(train_prep_ds)\n",
    "# image, y_true = next(itr)\n",
    "\n",
    "# # display('image', image)\n",
    "# display('y_true', y_true)\n",
    "# itr = iter(train_ds)\n",
    "# item = next(itr)\n",
    "# image, boxes = item['image'], item['faces']['bbox']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding boxes are transformed to HW grid. HW locations are based on CYCX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "# MAX_BOXES = 2\n",
    "# MAX_BOXES = 5\n",
    "# MAX_INPUT_BOXES = 2\n",
    "MAX_BOXES = 10\n",
    "MAX_INPUT_BOXES = 6\n",
    "\n",
    "def preprocess_as_center_grid(item):\n",
    "    image, boxes = item['image'], item['faces']['bbox']\n",
    "\n",
    "    # tf.print('image: ', image.shape)\n",
    "    # tf.print('boxes: ', boxes.shape)\n",
    "\n",
    "    # Resize image to IMG_SIZE\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    # Scatter boxes in a grid of (IMG_SIZE, IMG_SIZE)\n",
    "    box_grid = yxyx_to_cycxhw_grid(boxes, IMG_SIZE)\n",
    "\n",
    "    # tf.print('box_grid: ', box_grid, box_grid.shape)\n",
    "\n",
    "    return image, box_grid\n",
    "\n",
    "@tf.function\n",
    "def filter_empty_bboxes(item):\n",
    "    _, bboxes = item['image'], item['faces']['bbox']\n",
    "\n",
    "    return tf.shape(bboxes)[0] != 0\n",
    "\n",
    "# train_prep_ds = train_ds.filter(filter_empty_bboxes).map(preprocess_as_center_grid, num_parallel_calls=None)\n",
    "# val_prep_ds = val_ds.filter(filter_empty_bboxes).map(preprocess_as_center_grid, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# test_prep_ds = test_ds.map(preprocess_as_center_grid, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# bitr = iter(train_prep_ds.batch(2))\n",
    "# images, y_true = next(bitr)\n",
    "# images.shape, y_true.shape\n",
    "\n",
    "# itr = iter(train_prep_ds)\n",
    "# image, y_true = next(itr)\n",
    "\n",
    "# display('image', image)\n",
    "# display('y_true', y_true), tf.math.reduce_sum(mask, axis=-2)\n",
    "# itr = iter(train_ds)\n",
    "# item = next(itr)\n",
    "# image, boxes = item['image'], item['faces']['bbox']\n",
    "# image, mask = tf.function(preprocess_as_box_center_mask)(item)\n",
    "# image, y_true = preprocess_as_center_grid(item)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
