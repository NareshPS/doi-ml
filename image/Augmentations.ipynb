{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import importlib as imp\n",
    "\n",
    "from collections import namedtuple\n",
    "from random import sample, shuffle\n",
    "from functools import reduce\n",
    "from itertools import accumulate\n",
    "from math import floor, ceil, sqrt, log, pi\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers, utils, losses, models as mds, optimizers\n",
    "\n",
    "if imp.util.find_spec('aggdraw'): import aggdraw\n",
    "if imp.util.find_spec('tensorflow_addons'): from tensorflow_addons import layers as tfa_layers\n",
    "if imp.util.find_spec('tensorflow_models'): from official.vision.beta.ops import augment as visaugment\n",
    "if imp.util.find_spec('tensorflow_probability'): from tensorflow_probability import distributions as tfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset image size\n",
    "IMG_SIZE = 264\n",
    "N_CLASSES = 102\n",
    "\n",
    "def preprocess(image, *args):\n",
    "    image = tf.image.resize_with_pad(image, IMG_SIZE, IMG_SIZE)\n",
    "    image /= 255\n",
    "    return (image, *args)\n",
    "\n",
    "train_ds, val_ds = tfds.load(\n",
    "    'oxford_flowers102',\n",
    "    split=['train', 'validation'],\n",
    "    as_supervised=True,\n",
    "    read_config=tfds.ReadConfig(try_autocache=False)\n",
    ")\n",
    "\n",
    "train_ds = train_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal\"),\n",
    "  layers.RandomRotation(0.1),\n",
    "  # layers.RandomContrast(.2),\n",
    "])\n",
    "\n",
    "noaug_ds = train_ds.batch(2)\n",
    "tds = train_ds.batch(2)\n",
    "tds = tds.map(lambda x,y: (augs(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "itr, noaug_itr = iter(tds), iter(noaug_ds)\n",
    "\n",
    "fig, axes = plt.subplots(1,2, facecolor='w', edgecolor='k')\n",
    "next(itr), next(noaug_itr)\n",
    "\n",
    "axes[0].imshow(next(itr)[0][0])\n",
    "axes[1].imshow(next(noaug_itr)[0][0])\n",
    "\n",
    "axes[0].set_title('Augmented')\n",
    "axes[1].set_title('No Augmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MixUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "def expand_labels(image, label):\n",
    "    label = tf.one_hot(label, N_CLASSES)\n",
    "    return image, label\n",
    "\n",
    "def mix_values(item1, item2, l):\n",
    "    item = l*item1 + (1-l)*item2\n",
    "    return item\n",
    "\n",
    "def mix_fn(item1, item2):\n",
    "    image1, label1 = item1\n",
    "    image2, label2 = item2\n",
    "\n",
    "    l = tfd.Beta(5, 20).sample()\n",
    "\n",
    "    image = mix_values(image1, image2, l)\n",
    "    label = mix_values(label1, label2, l)\n",
    "    return image, label\n",
    "\n",
    "tds1 = train_ds.skip(1).map(expand_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "tds2 = tds1.shuffle(BATCH_SIZE*20)\n",
    "tds2 = tds1.skip(100)\n",
    "noaug_ds = tf.data.Dataset.zip((tds1, tds2)).batch(BATCH_SIZE)\n",
    "tds = noaug_ds.map(mix_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "vds = val_ds.batch(BATCH_SIZE).map(expand_labels, num_parallel_calls=tf.data.AUTOTUNE).cache()\n",
    "\n",
    "fig, axes = plt.subplots(1,3, facecolor='w', edgecolor='k')\n",
    "itr, noaug_itr = iter(tds), iter(noaug_ds)\n",
    "\n",
    "image, label = next(itr)[0]\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title('Augmented')\n",
    "\n",
    "# item1, item2 = next(noaug_itr)\n",
    "# image1, label1 = item1[0]\n",
    "# image2, label2 = item2[0]\n",
    "\n",
    "# axes[1].imshow(image1)\n",
    "# axes[2].imshow(image2)\n",
    "\n",
    "# axes[1].set_title('No Augmentation')\n",
    "# axes[2].set_title('No Augmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MixUp with Basic Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "augs = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal\"),\n",
    "  layers.RandomRotation(0.1),\n",
    "  layers.RandomContrast(.2),\n",
    "])\n",
    "\n",
    "def aug_fn(item1, item2):\n",
    "    image1, label1 = item1\n",
    "    image2, label2 = item2\n",
    "\n",
    "    image1 = augs(image1, training=True)\n",
    "    image2 = augs(image2, training=True)\n",
    "\n",
    "    return ((image1, label1), (image2, label2))\n",
    "\n",
    "def expand_labels(image, label):\n",
    "    label = tf.one_hot(label, N_CLASSES)\n",
    "    return image, label\n",
    "\n",
    "def mix_values(item1, item2, l):\n",
    "    item = l*item1 + (1-l)*item2\n",
    "    return item\n",
    "\n",
    "def mix_fn(item1, item2):\n",
    "    image1, label1 = item1\n",
    "    image2, label2 = item2\n",
    "\n",
    "    l = tfd.Beta(5, 20).sample()\n",
    "    tf.print(l)\n",
    "\n",
    "    image = mix_values(image1, image2, l)\n",
    "    label = mix_values(label1, label2, l)\n",
    "    return image, label\n",
    "\n",
    "tds1 = train_ds.skip(1).map(expand_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "tds2 = tds1.shuffle(BATCH_SIZE*20)\n",
    "# tds2 = tds1.skip(100)\n",
    "noaug_ds = tf.data.Dataset.zip((tds1, tds2)).batch(BATCH_SIZE)\n",
    "tds = noaug_ds.map(aug_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "tds = tds.map(mix_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "vds = val_ds.batch(BATCH_SIZE).map(expand_labels, num_parallel_calls=tf.data.AUTOTUNE).cache()\n",
    "\n",
    "fig, axes = plt.subplots(1,3, facecolor='w', edgecolor='k')\n",
    "itr, noaug_itr = iter(tds), iter(noaug_ds)\n",
    "\n",
    "image, label = next(itr)[0]\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title('Augmented')\n",
    "\n",
    "item1, item2 = next(noaug_itr)\n",
    "image1, _ = item1[0]\n",
    "image2, _ = item2[0]\n",
    "\n",
    "axes[1].imshow(image1)\n",
    "axes[2].imshow(image2)\n",
    "\n",
    "axes[1].set_title('No Augmentation')\n",
    "axes[2].set_title('No Augmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policies = [\n",
    "    [('Rotate', 0.7, 2), ('TranslateX', 0.3, 2)],\n",
    "    [('TranslateX', 0.3, 2), ('TranslateY', 0.4, 3)],\n",
    "    [('AutoContrast', 0.5, 3), ('Brightness', 0.9, 6)],\n",
    "    [('Rotate', 0.7, 2), ('Color', 0.2, 1)],\n",
    "]\n",
    "augmenter = visaugment.AutoAugment(policies=policies)\n",
    "\n",
    "def aug_fn(image, label):\n",
    "    image = tf.cast(image*255, tf.uint8)\n",
    "    image = augmenter.distort(image)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "tds = train_ds.map(aug_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "itr = iter(tds)\n",
    "plt.imshow(next(itr)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = visaugment.RandAugment()\n",
    "\n",
    "def randaug_pp(image, label):\n",
    "    image = tf.cast(image*255, tf.uint8)\n",
    "    image = augmenter.distort(image)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "tds = train_ds.map(randaug_pp, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "472baa808a066784c660228b7522f02c55b99d16f672674ca10b75b514659298"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
